{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scnn import SNN\n",
    "from scnn.optim import RAdam\n",
    "\n",
    "from data.data_augmentor import data_augment, batchify\n",
    "from tools.time_expector import TimeExpector\n",
    "from scnn.default_configs import *\n",
    "\n",
    "time_expector = TimeExpector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] : This is test run.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float\n",
    "\n",
    "test_run = True\n",
    "if test_run:\n",
    "    print('[WARNING] : This is test run.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing dataset: 21\n",
      "pre-processing dataset: 21\n"
     ]
    }
   ],
   "source": [
    "# FIXME\n",
    "my_laptop = True\n",
    "if my_laptop:\n",
    "    CACHE_FOLDER_PATH = \"/Users/aref/dvs-dataset/Cached\"\n",
    "    DATASET_FOLDER_PATH = \"/Users/aref/dvs-dataset/DvsGesture\"\n",
    "else:\n",
    "    CACHE_FOLDER_PATH = \"/home/aref/dataset/dvs-dataset\"\n",
    "    DATASET_FOLDER_PATH = \"/home/aref/dataset/dvs-dataset\"\n",
    "\n",
    "    \n",
    "def load_data(trail):\n",
    "    if test_run:\n",
    "        trail = 'acc_test' # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Remove this >>>>>>>>>>>>>>>>\n",
    "    \n",
    "    if trail.startswith('acc'):\n",
    "        max_augmentation = 1\n",
    "        augmentation = False\n",
    "    else:\n",
    "        max_augmentation = 3 if trail == 'train' else 1\n",
    "        augmentation = True\n",
    "    \n",
    "    trail = trail.replace('acc_', '')\n",
    "    return batchify(\n",
    "        trail,\n",
    "        DATASET_FOLDER_PATH,\n",
    "        CACHE_FOLDER_PATH,\n",
    "        condition_limit=['natural'],\n",
    "        batch_size=batch_size,\n",
    "        augmentation=augmentation,\n",
    "        max_augmentation=max_augmentation,\n",
    "        frame=60\n",
    "    )\n",
    "\n",
    "# calculate train dataset size\n",
    "dataset_size = [0., 0.]\n",
    "for x_batch, y_batch in load_data('train'):\n",
    "    dataset_size[0] += 1.\n",
    "    if dataset_size[0] % 64 == 1:\n",
    "        print('\\rpre-processing dataset: %d' % dataset_size[0], end='')\n",
    "print('\\rpre-processing dataset: %d' % dataset_size[0])\n",
    "for x_batch, y_batch in load_data('test'):\n",
    "    dataset_size[1] += 1.\n",
    "    if dataset_size[1] % 64 == 1:\n",
    "        print('\\rpre-processing dataset: %d' % dataset_size[1], end='')\n",
    "print('\\rpre-processing dataset: %d' % dataset_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseWithoutSynapse(torch.nn.Module):\n",
    "    IS_CONV = False\n",
    "    IS_SPIKING = True\n",
    "    HAS_PARAM = True\n",
    "\n",
    "    def __init__(self, input_shape, output_shape, spike_fn, w_init_mean=W_INIT_MEAN, w_init_std=W_INIT_STD,\n",
    "                 recurrent=False, lateral_connections=True, eps=EPSILON):\n",
    "        super(DenseWithoutSynapse, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.spike_fn = spike_fn\n",
    "        self.recurrent = recurrent\n",
    "        self.eps = eps\n",
    "        self.lateral_connections = lateral_connections\n",
    "\n",
    "        self.w_init_mean = w_init_mean\n",
    "        self.w_init_std = w_init_std\n",
    "\n",
    "        self.w = torch.nn.Parameter(torch.empty((input_shape, output_shape)), requires_grad=True)\n",
    "        if recurrent:\n",
    "            self.v = torch.nn.Parameter(torch.empty((output_shape, output_shape)), requires_grad=True)\n",
    "\n",
    "        self.beta = torch.nn.Parameter(torch.empty(1), requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.empty(output_shape), requires_grad=True)\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.clamp()\n",
    "        self.spk_rec_hist = None\n",
    "        self.mem_rec_hist = None\n",
    "        self.training = True\n",
    "\n",
    "\n",
    "    def get_trainable_parameters(self):\n",
    "        res = [\n",
    "            {'params': self.w},\n",
    "            {'params': self.b},\n",
    "            {'params': self.beta},\n",
    "        ]\n",
    "\n",
    "        if self.recurrent:\n",
    "            res.append({'params': self.v})\n",
    "        return res\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        nb_steps = x.shape[1]\n",
    "\n",
    "        h = torch.einsum(\"abc,cd->abd\", x, self.w)\n",
    "\n",
    "        # membrane potential \n",
    "        mem = torch.zeros((batch_size, self.output_shape), dtype=x.dtype, device=x.device)\n",
    "        spk = torch.zeros((batch_size, self.output_shape), dtype=x.dtype, device=x.device)\n",
    "\n",
    "        # output spikes recording\n",
    "        spk_rec = torch.zeros((batch_size, nb_steps, self.output_shape), dtype=x.dtype, device=x.device)\n",
    "        self.mem_rec_hist = torch.zeros((batch_size, nb_steps, self.output_shape), dtype=x.dtype, device=x.device)\n",
    "\n",
    "        if self.lateral_connections:\n",
    "            d = torch.einsum(\"ab, ac -> bc\", self.w, self.w)\n",
    "\n",
    "        norm = (self.w ** 2).sum(0)\n",
    "\n",
    "        for t in range(nb_steps):\n",
    "            # reset term\n",
    "            if self.lateral_connections:\n",
    "                rst = torch.einsum(\"ab,bc ->ac\", spk, d)\n",
    "            else:\n",
    "                rst = spk * self.b * norm\n",
    "\n",
    "            input_ = h[:, t, :]\n",
    "            if self.recurrent:\n",
    "                input_ = input_ + torch.einsum(\"ab,bc->ac\", spk, self.v)\n",
    "\n",
    "            mem = (mem - rst) * self.beta + input_ * (1. - self.beta)\n",
    "            mthr = torch.einsum(\"ab,b->ab\", mem, 1. / (norm + self.eps)) - self.b\n",
    "            spk = self.spike_fn(mthr)\n",
    "\n",
    "            spk_rec[:, t, :] = spk\n",
    "            self.mem_rec_hist[:, t, :] = mem\n",
    "\n",
    "            # save spk_rec for plotting\n",
    "        self.spk_rec_hist = spk_rec.detach().cpu().numpy()\n",
    "        self.mem_rec_hist = self.mem_rec_hist.detach().cpu().numpy()\n",
    "        return spk_rec\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.normal_(self.w, mean=self.w_init_mean, std=self.w_init_std * np.sqrt(1. / self.input_shape))\n",
    "        if self.recurrent:\n",
    "            torch.nn.init.normal_(self.v, mean=self.w_init_mean, std=self.w_init_std * np.sqrt(1. / self.output_shape))\n",
    "        torch.nn.init.normal_(self.beta, mean=0.7, std=0.01)\n",
    "        torch.nn.init.normal_(self.b, mean=1., std=0.01)\n",
    "\n",
    "    def clamp(self):\n",
    "        self.beta.data.clamp_(0., 1.)\n",
    "        self.b.data.clamp_(min=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseWithSynapse(torch.nn.Module):\n",
    "    IS_CONV = False\n",
    "    IS_SPIKING = True\n",
    "\n",
    "    def __init__(self, input_shape, output_shape, spike_fn, w_init_mean=W_INIT_MEAN, w_init_std=W_INIT_STD,\n",
    "                 recurrent=False, lateral_connections=True, eps=EPSILON):\n",
    "        super(DenseWithSynapse, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.spike_fn = spike_fn\n",
    "        self.recurrent = recurrent\n",
    "        self.eps = eps\n",
    "        self.lateral_connections = lateral_connections\n",
    "\n",
    "        self.w_init_mean = w_init_mean\n",
    "        self.w_init_std = w_init_std\n",
    "\n",
    "        self.w = torch.nn.Parameter(torch.empty((input_shape, output_shape)), requires_grad=True)\n",
    "        if recurrent:\n",
    "            self.v = torch.nn.Parameter(torch.empty((output_shape, output_shape)), requires_grad=True)\n",
    "\n",
    "        tau_mem = 10e-3\n",
    "        tau_syn = 5e-3\n",
    "        time_step = 1e-3\n",
    "\n",
    "        self._alpha = float(np.exp(-time_step / tau_syn))\n",
    "        self._beta = float(np.exp(-time_step / tau_mem))\n",
    "\n",
    "        self.b = torch.nn.Parameter(torch.empty(output_shape), requires_grad=True)\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.clamp()\n",
    "        self.spk_rec_hist = None\n",
    "        self.mem_rec_hist = None\n",
    "        self.training = True\n",
    "\n",
    "    def get_trainable_parameters(self):\n",
    "        res = [\n",
    "            {'params': self.w},\n",
    "            {'params': self.b},\n",
    "        ]\n",
    "\n",
    "        if self.recurrent:\n",
    "            res.append({'params': self.v})\n",
    "        return res\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        nb_steps = x.shape[1]\n",
    "\n",
    "        h1 = torch.einsum(\"abc,cd->abd\", (x, self.w))\n",
    "        syn = torch.zeros((batch_size, self.output_shape), device=x.device, dtype=x.dtype)\n",
    "        mem = torch.zeros((batch_size, self.output_shape), device=x.device, dtype=x.dtype)\n",
    "\n",
    "        spk_rec = torch.zeros((batch_size, nb_steps, self.output_shape), dtype=x.dtype, device=x.device)\n",
    "        mem_rec = torch.zeros((batch_size, nb_steps, self.output_shape), dtype=x.dtype, device=x.device)\n",
    "\n",
    "        # Compute hidden layer activity\n",
    "        for t in range(nb_steps):\n",
    "            mthr = mem - 1.0\n",
    "            out = self.spike_fn(mthr)\n",
    "            rst = torch.zeros_like(mem)\n",
    "            c = (mthr > 0)\n",
    "            rst[c] = torch.ones_like(mem)[c]\n",
    "\n",
    "            new_syn = self._alpha * syn + h1[:, t]\n",
    "            new_mem = self._beta * mem + syn - rst\n",
    "\n",
    "            mem = new_mem\n",
    "            syn = new_syn\n",
    "\n",
    "            mem_rec[:, t, :] = mem\n",
    "            spk_rec[:, t, :] = out\n",
    "\n",
    "        self.spk_rec_hist = spk_rec.detach().cpu().numpy()\n",
    "        self.mem_rec_hist = mem_rec.detach().cpu().numpy()\n",
    "        return spk_rec\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.normal_(self.w, mean=self.w_init_mean, std=self.w_init_std * np.sqrt(1. / self.input_shape))\n",
    "\n",
    "    def clamp(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "beta = float(np.exp(-time_step / tau_mem))\n",
    "weight_scale = 7*(1.0 - beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network with synapse:\n",
      "Epoch: 0 [===========================================================>] 100%      | loss=2.474 val_loss=2.452\n",
      "train_accuracy=20.98%  |  valid_accuracy=20.98%\n",
      "[operation finished at 2020-04-22 09:33:15  -  took 14 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:24]\n",
      "Epoch: 1 [===========================================================>] 100%      | loss=2.436 val_loss=2.406\n",
      "train_accuracy=19.79%  |  valid_accuracy=20.54%\n",
      "[operation finished at 2020-04-22 09:33:27  -  took 11 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:19]\n",
      "Epoch: 2 [===========================================================>] 100%      | loss=2.383 val_loss=2.356\n",
      "train_accuracy=20.98%  |  valid_accuracy=21.43%\n",
      "[operation finished at 2020-04-22 09:33:39  -  took 11 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:16]\n",
      "Epoch: 3 [===========================================================>] 100%      | loss=2.340 val_loss=2.310\n",
      "train_accuracy=23.51%  |  valid_accuracy=22.92%\n",
      "[operation finished at 2020-04-22 09:33:51  -  took 12 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:13]\n",
      "Epoch: 4 [===========================================================>] 100%      | loss=2.295 val_loss=2.270\n",
      "train_accuracy=26.19%  |  valid_accuracy=25.60%\n",
      "[operation finished at 2020-04-22 09:34:03  -  took 12 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:11]\n",
      "Epoch: 5 [===========================================================>] 100%      | loss=2.257 val_loss=2.229\n",
      "train_accuracy=30.06%  |  valid_accuracy=29.91%\n",
      "[operation finished at 2020-04-22 09:34:15  -  took 11 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:08]\n",
      "Epoch: 6 [===========================================================>] 100%      | loss=2.216 val_loss=2.183\n",
      "train_accuracy=31.40%  |  valid_accuracy=31.40%\n",
      "[operation finished at 2020-04-22 09:34:27  -  took 11 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:07]\n",
      "Epoch: 7 [===========================================================>] 100%      | loss=2.171 val_loss=2.144\n",
      "train_accuracy=32.14%  |  valid_accuracy=31.85%\n",
      "[operation finished at 2020-04-22 09:34:39  -  took 11 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:05]\n",
      "Epoch: 8 [===========================================================>] 100%      | loss=2.114 val_loss=2.082\n",
      "train_accuracy=33.78%  |  valid_accuracy=33.93%\n",
      "[operation finished at 2020-04-22 09:34:51  -  took 12 seconds]\n",
      "[expecting to finish at 2020-04-22 09:35:04]\n",
      "Epoch: 9 [===========================================================>] 100%      | loss=2.067 val_loss=2.040\n",
      "train_accuracy=36.76%  |  valid_accuracy=36.61%\n",
      "[operation finished at 2020-04-22 09:35:03  -  took 12 seconds]\n",
      "\n",
      "----------------------------------------\n",
      "Final Train Accuracy=36.46%\n",
      "Final Test Accuracy=35.86%\n"
     ]
    }
   ],
   "source": [
    "print('Network with synapse:')\n",
    "\n",
    "network = SNN(device=device, dtype=dtype)\n",
    "network.time_expector = time_expector\n",
    "\n",
    "\n",
    "network.add_layer(DenseWithSynapse,\n",
    "    input_shape=4096,\n",
    "    output_shape=128,              \n",
    "    w_init_mean=0.0,\n",
    "    w_init_std=weight_scale\n",
    ")\n",
    "\n",
    "network.add_readout(output_shape=12,\n",
    "                    time_reduction=\"max\" # mean or max\n",
    ")\n",
    "\n",
    "network.compile()\n",
    "network = network.to(network.device, network.dtype) # FIXME: this is a bug, fix it!\n",
    "\n",
    "\n",
    "# opt = RAdam(network.get_trainable_parameters())\n",
    "opt = torch.optim.SGD(network.get_trainable_parameters(), lr=1e-3, momentum=0.9)\n",
    "network.fit(load_data, epochs=nb_epochs, optimizer=opt, dataset_size=dataset_size)\n",
    "    \n",
    "print('\\n----------------------------------------')\n",
    "train_accuracy = network.compute_classification_accuracy(load_data('acc_train'))\n",
    "print(\"Final Train Accuracy=%.2f%%\"%(train_accuracy * 100.))\n",
    "test_accuracy = network.compute_classification_accuracy(load_data('acc_test'))\n",
    "print(\"Final Test Accuracy=%.2f%%\"%(test_accuracy * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network without synapse:\n",
      "[expecting to finish at 2020-04-22 09:37:18]\n",
      "Epoch: 0 [===========================================================>] 100%      | loss=2.485 val_loss=2.483\n",
      "train_accuracy=19.05%  |  valid_accuracy=18.90%\n",
      "[operation finished at 2020-04-22 09:35:23  -  took 13 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:20]\n",
      "Epoch: 1 [===========================================================>] 100%      | loss=2.481 val_loss=2.479\n",
      "train_accuracy=18.90%  |  valid_accuracy=19.64%\n",
      "[operation finished at 2020-04-22 09:35:37  -  took 14 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:22]\n",
      "Epoch: 2 [===========================================================>] 100%      | loss=2.476 val_loss=2.474\n",
      "train_accuracy=18.75%  |  valid_accuracy=19.20%\n",
      "[operation finished at 2020-04-22 09:35:50  -  took 13 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:22]\n",
      "Epoch: 3 [===========================================================>] 100%      | loss=2.472 val_loss=2.469\n",
      "train_accuracy=19.49%  |  valid_accuracy=18.90%\n",
      "[operation finished at 2020-04-22 09:36:03  -  took 13 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:22]\n",
      "Epoch: 4 [===========================================================>] 100%      | loss=2.468 val_loss=2.467\n",
      "train_accuracy=19.20%  |  valid_accuracy=19.49%\n",
      "[operation finished at 2020-04-22 09:36:16  -  took 13 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:22]\n",
      "Epoch: 5 [===========================================================>] 100%      | loss=2.464 val_loss=2.462\n",
      "train_accuracy=19.64%  |  valid_accuracy=19.35%\n",
      "[operation finished at 2020-04-22 09:36:32  -  took 15 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:25]\n",
      "Epoch: 6 [===========================================================>] 100%      | loss=2.460 val_loss=2.458\n",
      "train_accuracy=19.64%  |  valid_accuracy=19.35%\n",
      "[operation finished at 2020-04-22 09:36:46  -  took 14 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:27]\n",
      "Epoch: 7 [===========================================================>] 100%      | loss=2.456 val_loss=2.455\n",
      "train_accuracy=19.20%  |  valid_accuracy=19.20%\n",
      "[operation finished at 2020-04-22 09:37:01  -  took 14 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:28]\n",
      "Epoch: 8 [===========================================================>] 100%      | loss=2.455 val_loss=2.452\n",
      "train_accuracy=19.05%  |  valid_accuracy=19.35%\n",
      "[operation finished at 2020-04-22 09:37:17  -  took 15 seconds]\n",
      "[expecting to finish at 2020-04-22 09:37:30]\n",
      "Epoch: 9 [===========================================================>] 100%      | loss=2.450 val_loss=2.447\n",
      "train_accuracy=19.05%  |  valid_accuracy=19.20%\n",
      "[operation finished at 2020-04-22 09:37:31  -  took 14 seconds]\n",
      "\n",
      "----------------------------------------\n",
      "Final Train Accuracy=19.05%\n",
      "Final Test Accuracy=19.79%\n"
     ]
    }
   ],
   "source": [
    "print('Network without synapse:')\n",
    "\n",
    "network = SNN(device=device, dtype=dtype)\n",
    "network.time_expector = time_expector\n",
    "\n",
    "\n",
    "network.add_layer(DenseWithoutSynapse,\n",
    "    input_shape=4096,\n",
    "    output_shape=128,              \n",
    "    w_init_mean=0.0,\n",
    "    w_init_std=weight_scale\n",
    ")\n",
    "\n",
    "network.add_readout(output_shape=12,\n",
    "                    time_reduction=\"max\" # mean or max\n",
    ")\n",
    "\n",
    "network.compile()\n",
    "network = network.to(network.device, network.dtype) # FIXME: this is a bug, fix it!\n",
    "\n",
    "\n",
    "# opt = RAdam(network.get_trainable_parameters())\n",
    "opt = torch.optim.SGD(network.get_trainable_parameters(), lr=1e-3, momentum=0.9)\n",
    "network.fit(load_data, epochs=nb_epochs, optimizer=opt, dataset_size=dataset_size)\n",
    "    \n",
    "print('\\n----------------------------------------')\n",
    "train_accuracy = network.compute_classification_accuracy(load_data('acc_train'))\n",
    "print(\"Final Train Accuracy=%.2f%%\"%(train_accuracy * 100.))\n",
    "test_accuracy = network.compute_classification_accuracy(load_data('acc_test'))\n",
    "print(\"Final Test Accuracy=%.2f%%\"%(test_accuracy * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
