{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_augmentor import data_augment, batchify\n",
    "from tools.time_expector import TimeExpector\n",
    "from tools.notify import notify\n",
    "from sys import stdout\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "# import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from time import sleep\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu...\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "tx = TimeExpector()\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda...')\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    print('using cpu...')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FOLDER_PATH = \"/Users/aref/dvs-dataset/Cached/\"\n",
    "DATASET_FOLDER_PATH = \"/Users/aref/dvs-dataset/DvsGesture/\"\n",
    "    \n",
    "nb_image_height = 64\n",
    "nb_image_weight = 64\n",
    "nb_inputs  = nb_image_height*nb_image_weight\n",
    "nb_hidden  = 64\n",
    "nb_outputs = 12\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(trail):\n",
    "    if trail.startswith('acc'):\n",
    "        max_augmentation = 1\n",
    "        augmentation = False\n",
    "    else:\n",
    "        max_augmentation = 3 if trail == 'train' else 1\n",
    "        augmentation = True\n",
    "    \n",
    "    trail = trail.replace('acc_', '')\n",
    "    return batchify(\n",
    "        trail,\n",
    "        DATASET_FOLDER_PATH,\n",
    "        CACHE_FOLDER_PATH,\n",
    "        condition_limit=['natural'],\n",
    "        batch_size=batch_size,\n",
    "        augmentation=augmentation,\n",
    "        max_augmentation=max_augmentation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    global w1, w2, loss_histogram_train, loss_histogram_test\n",
    "    weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "    w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "    torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "    w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "    torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "    \n",
    "    loss_histogram_train = []\n",
    "    loss_histogram_test = []\n",
    "    print('init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSpike(torch.autograd.Function):\n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SuperSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "spike_fn  = SuperSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "#     print inputs.shape, 'vs', w1.shape\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    print('min', torch.min(h1), '| mean', torch.mean(h1), ' | max', torch.max(h1))\n",
    "    raise\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = [mem]\n",
    "    spk_rec = [mem]\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = torch.zeros_like(mem)\n",
    "        c   = (mthr > 0)\n",
    "        rst[c] = torch.ones_like(mem)[c]\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = beta*mem +syn -rst\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prog_print(items, max_items):\n",
    "    percentage = 100*items/max_items\n",
    "    items = int(items)\n",
    "    max_items = int(max_items)\n",
    "    \n",
    "    stdout.write('\\r')\n",
    "    stdout.write('  %.2f%%' % percentage)\n",
    "    stdout.write('  [=')\n",
    "    if items < max_items:\n",
    "        stdout.write('=' * (items-1))\n",
    "        stdout.write('>')\n",
    "        stdout.write('.' * (max_items - items))\n",
    "    else:\n",
    "        stdout.write('=' * (items))\n",
    "    stdout.write(']  ')\n",
    "    stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_one_batch(x_local, y_local, apply_optimization, params, optimizer, log_softmax_fn, loss_fn):\n",
    "    x_local = np.reshape(x_local, (batch_size, nb_steps, 64*64))\n",
    "    x_local = torch.from_numpy(x_local).type(dtype)\n",
    "    y_local = torch.from_numpy(y_local.astype(np.long))\n",
    "\n",
    "    output,_ = run_snn(x_local)\n",
    "    m,_=torch.max(output,1)\n",
    "    log_p_y = log_softmax_fn(m)\n",
    "    loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "    if apply_optimization:\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "    return loss_val.item()\n",
    "    \n",
    "\n",
    "def train(learning_rate, nb_epochs):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(params, lr=learning_rate, betas=(0.9,0.999))\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        tx.tick(nb_epochs - e)\n",
    "        local_loss_train = []\n",
    "        local_loss_test = []\n",
    "        print('Epoch %d/%d' % (e+1, nb_epochs))\n",
    "        \n",
    "        pc = 0\n",
    "        for x_local, y_local in load_data('train'):\n",
    "            prog_print(pc, 55)\n",
    "            pc += .1\n",
    "            loss = train_on_one_batch(x_local, y_local, True, params, optimizer, log_softmax_fn, loss_fn)\n",
    "            local_loss_train.append(loss)\n",
    "            \n",
    "        for x_local, y_local in load_data('test'):\n",
    "            prog_print(pc, 55)\n",
    "            pc += .1\n",
    "            loss = train_on_one_batch(x_local, y_local, False, params, optimizer, log_softmax_fn, loss_fn)\n",
    "            local_loss_test.append(loss)\n",
    "            \n",
    "        mean_loss_train = np.mean(local_loss_train)\n",
    "        mean_loss_test = np.mean(local_loss_test)\n",
    "        print('- loss (train=%.5f , test=%.5f)' % (mean_loss_train, mean_loss_test))\n",
    "        loss_histogram_train.append(mean_loss_train)\n",
    "        loss_histogram_test.append(mean_loss_test)\n",
    "        tx.tock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(trail):\n",
    "    accs = []\n",
    "    heatmap = np.zeros((nb_outputs, nb_outputs))\n",
    "    \n",
    "    for x_local, y_local in load_data('acc_%s' % trail):\n",
    "        x_local = np.reshape(x_local, (batch_size, nb_steps, 64*64))\n",
    "        x_local = torch.from_numpy(x_local).type(dtype)\n",
    "        output, _ = run_snn(x_local)\n",
    "        m, _ = torch.max(output,1)\n",
    "        _, am = torch.max(m,1)\n",
    "        accs.append(np.mean(y_local == am.detach().cpu().numpy() ))\n",
    "        \n",
    "        for i in range(y_local.shape[0]):\n",
    "            heatmap[y_local[i], am[i]] += 1\n",
    "    return accs, heatmap\n",
    "\n",
    "def print_and_plot_accuracy_metrics():\n",
    "    accs_train, heatmap_train = compute_classification_accuracy('train')\n",
    "    accs_test, heatmap_test = compute_classification_accuracy('test')\n",
    "\n",
    "    print(\"Train accuracy: %f\" % (np.mean(np.array(accs_train))))\n",
    "    print(\"Test accuracy: %f\" % (np.mean(np.array(accs_test))))\n",
    "\n",
    "    sns.heatmap(heatmap_train)\n",
    "    plt.title('Train Result Heatmap (%.1f%%)' % (np.mean(np.array(accs_train))*100))\n",
    "    plt.xlabel(\"Truth\")\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.heatmap(heatmap_test)\n",
    "    plt.title('Test Result Heatmap (%.1f%%)' % (np.mean(np.array(accs_test))*100))\n",
    "    plt.xlabel(\"Truth\")\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_loss_diagrams():\n",
    "    plt.figure(figsize=(3.3,2), dpi=150)\n",
    "    plt.plot(loss_histogram_train, 'b', label='train')\n",
    "    plt.plot(loss_histogram_test, 'r--', label='test')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    sns.despine()\n",
    "\n",
    "def plot_voltage_traces(mem, spk=None, dim=(1,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = (mem+spike_height*spk).detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_neuron_activities():\n",
    "    for x_local, _ in load_data('acc_train'):\n",
    "        x_local = np.reshape(x_local, (batch_size, nb_steps, 64*64))\n",
    "        x_local = torch.from_numpy(x_local).type(dtype)\n",
    "        output, other_recordings = run_snn(x_local)\n",
    "        mem_rec, spk_rec = other_recordings\n",
    "        break\n",
    "\n",
    "    print('mem_rec/spk_rec data')\n",
    "    fig=plt.figure(dpi=100)\n",
    "    plot_voltage_traces(mem_rec, spk_rec)\n",
    "\n",
    "    print('Output data')\n",
    "    fig=plt.figure(dpi=100)\n",
    "    plot_voltage_traces(output)\n",
    "\n",
    "    print('Spike Activity')\n",
    "    nb_plt = 4\n",
    "    gs = GridSpec(1,nb_plt)\n",
    "    fig= plt.figure(figsize=(7,3),dpi=150)\n",
    "    for i in range(nb_plt):\n",
    "        plt.subplot(gs[i])\n",
    "        plt.imshow(spk_rec[i].detach().cpu().numpy().T,cmap=plt.cm.gray_r, origin=\"lower\" )\n",
    "        if i==0:\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Units\")\n",
    "\n",
    "        sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ *Simple-SNN* has started.\n",
      "init\n",
      "Epoch 1/10\n",
      "  0.00%  [=>.......................................................]  min tensor(-0.9605, grad_fn=<MinBackward1>) | mean tensor(-0.0028, grad_fn=<MeanBackward0>)  | max tensor(1.0036, grad_fn=<MaxBackward1>)\n",
      "📛 *Simple-SNN* failed!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-90707ec42e1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0minit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mshould_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mplot_loss_diagrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mplot_neuron_activities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-02b0aa9a1099>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(learning_rate, nb_epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprog_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mpc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_softmax_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mlocal_loss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-02b0aa9a1099>\u001b[0m in \u001b[0;36mtrain_on_one_batch\u001b[0;34m(x_local, y_local, apply_optimization, params, optimizer, log_softmax_fn, loss_fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_snn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_softmax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-246de06eeab6>\u001b[0m in \u001b[0;36mrun_snn\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"abc,cd->abd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'| mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' | max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    notify('*Simple-SNN* has started.', mark='info')\n",
    "    for i in range(10):\n",
    "        if should_init:\n",
    "            init_network()\n",
    "            should_init = False\n",
    "        train(learning_rate=2e-4, nb_epochs=10)\n",
    "        plot_loss_diagrams()\n",
    "        plot_neuron_activities()\n",
    "        print_and_plot_accuracy_metrics()\n",
    "        notify('*Simple-SNN* Trail #%d finished.' % i, mark='info')\n",
    "    notify('*Simple-SNN* finished!', mark='ok')\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\n-- canceled --')\n",
    "except:\n",
    "    notify('*Simple-SNN* failed!', mark='error')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
