{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_augmentor import data_augment, batchify\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from time import sleep\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu...\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda...')\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    print('using cpu...')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FOLDER_PATH = \"/Users/aref/dvs-dataset/Cached/\"\n",
    "DATASET_FOLDER_PATH = \"/Users/aref/dvs-dataset/DvsGesture/\"\n",
    "    \n",
    "nb_image_height = 64\n",
    "nb_image_weight = 64\n",
    "nb_inputs  = nb_image_height*nb_image_weight\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 12\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "print('init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSpike(torch.autograd.Function):\n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SuperSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SuperSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SuperSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    print inputs.shape, 'vs', w1.shape\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = [mem]\n",
    "    spk_rec = [mem]\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = torch.zeros_like(mem)\n",
    "        c   = (mthr > 0)\n",
    "        rst[c] = torch.ones_like(mem)[c]\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = beta*mem +syn -rst\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr=2e-3, nb_epochs=10):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in batchify('train',\n",
    "                                         DATASET_FOLDER_PATH,\n",
    "                                         CACHE_FOLDER_PATH,\n",
    "                                         condition_limit=['natural']):\n",
    "            x_local = np.reshape(x_local, (16, 100, 64*64))\n",
    "            x_local = torch.from_numpy(x_local).type(dtype)\n",
    "            y_local = torch.from_numpy(y_local.astype(np.long))\n",
    "            \n",
    "#             print '>>>>>', x_local.shape, y_local.shape\n",
    "#             print y_local\n",
    "\n",
    "            output,_ = run_snn(x_local)\n",
    "            m,_=torch.max(output,1)\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "            loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100, 4096]) vs torch.Size([4096, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (16) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b781ab533188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-96013f459b5b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr, nb_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#             print y_local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_snn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_softmax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-23ddb0323f03>\u001b[0m in \u001b[0;36mrun_snn\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mnew_syn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msyn\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mnew_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmem\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0msyn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mrst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (16) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "loss_hist = train(lr=2e-4, nb_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b47f93772318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_hist' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 495x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2afb2665951b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training accuracy: %.3f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_classification_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy: %.3f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_classification_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_classification_accuracy(x_data, y_data):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    max_count = len(x_data) / batch_size\n",
    "    for counter in range(max_count):\n",
    "        i = counter*batch_size\n",
    "        x_local = torch.from_numpy(x_data[i:i+batch_size, :, :]).type(dtype)\n",
    "        y_local = torch.from_numpy(y_data[i:i+batch_size])\n",
    "        output, _ = run_snn(x_local)\n",
    "        m, _ = torch.max(output,1) # max over time\n",
    "        _, am = torch.max(m,1)      # argmax over output units\n",
    "        tmp = np.mean((y_local.type(torch.long)==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)\n",
    "\n",
    "\n",
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(x_train, y_train)))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3fe396761615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_recordings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_snn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmem_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspk_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother_recordings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(1,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = (mem+spike_height*spk).detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "def get_mini_batch(x_data, y_data, shuffle=False):\n",
    "    max_count = x_data.shape[0] / batch_size\n",
    "    for counter in range(max_count):\n",
    "        i = counter*batch_size\n",
    "        x_local = x_data[i:i+batch_size, :, :]\n",
    "        y_local = y_data[i:i+batch_size]\n",
    "        return x_local, y_local\n",
    "\n",
    "x_batch, y_batch = get_mini_batch(x_train, y_train)\n",
    "output, other_recordings = run_snn(torch.from_numpy(x_batch).type(dtype))\n",
    "mem_rec, spk_rec = other_recordings\n",
    "\n",
    "fig=plt.figure(dpi=100)\n",
    "plot_voltage_traces(mem_rec, spk_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-efaf8f43ebf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_voltage_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(dpi=100)\n",
    "plot_voltage_traces(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spk_rec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ea1a1a2f6506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_plt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spk_rec' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1050x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the hiddden layer spiking activity for some input stimuli\n",
    "\n",
    "nb_plt = 4\n",
    "gs = GridSpec(1,nb_plt)\n",
    "fig= plt.figure(figsize=(7,3),dpi=150)\n",
    "for i in range(nb_plt):\n",
    "    plt.subplot(gs[i])\n",
    "    plt.imshow(spk_rec[i].detach().cpu().numpy().T,cmap=plt.cm.gray_r, origin=\"lower\" )\n",
    "    if i==0:\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Units\")\n",
    "\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
