{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from time import sleep\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER_PATH = '/Users/aref/dvs-dataset/DvsGesture'\n",
    "\n",
    "nb_image_height = 64\n",
    "nb_image_weight = 64\n",
    "nb_inputs  = nb_image_height*nb_image_weight\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 12\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 200\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu...\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda...')\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    print('using cpu...')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file list:\n",
    "train_trail_file = 'trials_to_train.txt'\n",
    "test_trail_file = 'trials_to_test.txt'\n",
    "\n",
    "def load_trail_files(trail_file):\n",
    "    file_list = []\n",
    "    with open(os.path.join(DATASET_FOLDER_PATH, trail_file), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            aedat_file = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            csv_file = aedat_file.replace('.aedat', '_labels.csv')\n",
    "            file_list.append((\n",
    "                os.path.join(DATASET_FOLDER_PATH, aedat_file),\n",
    "                os.path.join(DATASET_FOLDER_PATH, csv_file)\n",
    "            ))\n",
    "    return file_list\n",
    "\n",
    "file_list_train = load_trail_files(train_trail_file)\n",
    "file_list_test = load_trail_files(test_trail_file)\n",
    "\n",
    "def get_label(timestamp):\n",
    "    for t in event_labels.keys():\n",
    "        if t > timestamp:\n",
    "            return event_labels[t]\n",
    "    return 0\n",
    "\n",
    "def get_label_text(timestamp):\n",
    "    return gesture_mapping[get_label(timestamp)]\n",
    "\n",
    "# mapping\n",
    "gesture_mapping = {\n",
    "    0: 'no_gesture',\n",
    "    1: 'hand_clapping',\n",
    "    2: 'right_hand_wave',\n",
    "    3: 'left_hand_wave',\n",
    "    4: 'right_arm_clockwise',\n",
    "    5: 'right_arm_counter_clockwise',\n",
    "    6: 'left_arm_clockwise',\n",
    "    7: 'left_arm_counter_clockwise',\n",
    "    8: 'arm_roll',\n",
    "    9: 'air_drums',\n",
    "    10: 'air_guitar',\n",
    "    11: 'other_gestures',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 98 ----------------------------------------------------------\n",
      "    reading \"/Users/aref/dvs-dataset/DvsGesture/user01_fluorescent.aedat\"\n",
      "loading dataset...\n",
      "done!\n",
      "    processing file\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'event_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eaa1abc98b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'    saved!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mcache_trail_set_from_file_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_list_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0mcache_trail_set_from_file_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_list_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-eaa1abc98b52>\u001b[0m in \u001b[0;36mcache_trail_set_from_file_list\u001b[0;34m(trail, file_list)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mmean_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmin_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mmean_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel_began_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mmax_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mmin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b699bcea6177>\u001b[0m in \u001b[0;36mget_label\u001b[0;34m(timestamp)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mevent_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'event_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from reader import read_file_all\n",
    "from collections import OrderedDict\n",
    "\n",
    "def read_event_labels(path):\n",
    "    label_began_time = None\n",
    "    event_labels = OrderedDict()\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            label, start, end = line.strip().split(',')\n",
    "#             print '%5s\\t%15s\\t%15s' % (label, start, end)\n",
    "            try:\n",
    "                label = int(label)\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if label_began_time is None:\n",
    "                label_began_time = start\n",
    "\n",
    "            event_labels[start] = 0\n",
    "            event_labels[end] = label\n",
    "    return event_labels, label_began_time\n",
    "\n",
    "\n",
    "def cache_trail_set_from_file_list(trail, file_list):\n",
    "    counter = 0\n",
    "    for file_name_set in file_list:\n",
    "        x_train = np.zeros([0, 100, nb_inputs])\n",
    "        y_train = []\n",
    "        counter += 1\n",
    "        print '%d out of %d ----------------------------------------------------------' % (counter, len(file_list))\n",
    "        print '    reading \"%s\"' % file_name_set[0]\n",
    "        event_labels, label_began_time = read_event_labels(file_name_set[1])\n",
    "        event_list = read_file_all(file_name_set[0])\n",
    "\n",
    "        print('    processing file')\n",
    "        img = np.zeros([nb_image_weight, nb_image_height])\n",
    "\n",
    "        max_time = None\n",
    "        min_time = None\n",
    "        begin_time = None\n",
    "        end_time = None\n",
    "\n",
    "        prev_label = None\n",
    "        frame_counter = 0\n",
    "        x_frame = np.zeros([1, 100, nb_inputs])\n",
    "        for e in event_list:\n",
    "            if e != 'clear':\n",
    "                img[int(e['y']/2), int(e['x']/2)] = 1 # if e['polarity'] == 1 else 0\n",
    "                if e['timestamp'] < min_time or min_time is None:\n",
    "                    min_time = e['timestamp']\n",
    "                if e['timestamp'] > max_time or max_time is None:\n",
    "                    max_time = e['timestamp']\n",
    "            else:\n",
    "                if begin_time is None:\n",
    "                    begin_time = min_time\n",
    "                end_time = max_time\n",
    "                mean_time = (max_time + min_time)/2\n",
    "                mean_time = mean_time - begin_time + label_began_time\n",
    "                label = get_label(mean_time)\n",
    "                max_time = None\n",
    "                min_time = None\n",
    "                if prev_label is None:\n",
    "                    prev_label = label\n",
    "                elif prev_label != label:\n",
    "                    prev_label = None\n",
    "                    x_frame = np.zeros([1, 100, nb_inputs])\n",
    "                    img = np.zeros([nb_image_weight, nb_image_height])\n",
    "                    frame_counter = 0\n",
    "                    continue\n",
    "\n",
    "                if frame_counter == 100:\n",
    "                    y_train.append(label)\n",
    "                    x_train = np.append(x_train, x_frame, axis=0)\n",
    "                    x_frame = np.zeros([1, 100, nb_inputs])\n",
    "                    frame_counter = 0\n",
    "                else:\n",
    "                    x_frame[0, frame_counter, :] = img.flatten()\n",
    "                    frame_counter += 1\n",
    "                img = np.zeros([nb_image_weight, nb_image_height])\n",
    "\n",
    "        y_train = np.array(y_train)\n",
    "        print '    ', x_train.shape, ' ~> ', y_train.shape\n",
    "        np.save(file=\"x_%s_cache_%d\" % (trail, counter), arr=x_train)\n",
    "        np.save(file=\"y_%s_cache_%d\" % (trail, counter), arr=y_train)\n",
    "        print '    saved!'\n",
    "        \n",
    "cache_trail_set_from_file_list('train', file_list_train)\n",
    "cache_trail_set_from_file_list('test', file_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_cache_generator(train_set=True):\n",
    "    counter = 0\n",
    "    file_list = file_list_train if train_set else file_list_test\n",
    "    for file_name_set in file_list:\n",
    "        counter += 1\n",
    "        x_train = np.load(file=\"x_train_cache_%d.npy\" % counter)\n",
    "        y_train = np.load(file=\"y_train_cache_%d.npy\" % counter)\n",
    "        yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "loss_hist = []\n",
    "\n",
    "print('init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSpike(torch.autograd.Function):\n",
    "    scale = 50.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input/(SuperSpike.scale*torch.abs(input)+1.0)**2\n",
    "#         return grad_input\n",
    "    \n",
    "spike_fn  = SuperSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = [mem]\n",
    "    spk_rec = [mem]\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = torch.zeros_like(mem)\n",
    "        c   = (mthr > 0)\n",
    "        rst[c] = torch.ones_like(mem)[c]\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = beta*mem +syn -rst\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr=2e-3, nb_epochs=10, loss_hist=None):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    if loss_hist is None:\n",
    "        loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        print_counter = 0\n",
    "        local_loss = []\n",
    "        for x_data, y_data in from_cache_generator():\n",
    "            if print_counter % 4 == 0:\n",
    "                print '.',\n",
    "            print_counter += 1\n",
    "            \n",
    "            y_data = y_data.astype(np.long)\n",
    "            max_count = x_data.shape[0] / batch_size\n",
    "            for counter in range(max_count):\n",
    "                i = counter*batch_size\n",
    "                x_local = torch.from_numpy(x_data[i:i+batch_size, :, :]).type(dtype)\n",
    "                y_local = torch.from_numpy(y_data[i:i+batch_size])\n",
    "\n",
    "                if x_local.shape[0] != batch_size:\n",
    "                    continue\n",
    "                \n",
    "                output,_ = run_snn(x_local)\n",
    "                m,_=torch.max(output,1)\n",
    "                log_p_y = log_softmax_fn(m)\n",
    "                loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "                local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "loss_hist = train(lr=2e-4, nb_epochs=10, loss_hist=loss_hist)\n",
    "\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.856\n",
      "Test accuracy: 0.863\n"
     ]
    }
   ],
   "source": [
    "def compute_classification_accuracy(x_data, y_data):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    max_count = len(x_data) / batch_size\n",
    "    for counter in range(max_count):\n",
    "        i = counter*batch_size\n",
    "        x_local = torch.from_numpy(x_data[i:i+batch_size, :, :]).type(dtype)\n",
    "        y_local = torch.from_numpy(y_data[i:i+batch_size])\n",
    "        output, _ = run_snn(x_local)\n",
    "        m, _ = torch.max(output,1) # max over time\n",
    "        _, am = torch.max(m,1)      # argmax over output units\n",
    "        tmp = np.mean((y_local.type(torch.long)==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)\n",
    "\n",
    "errors = []\n",
    "for x_data, y_data in from_cache_generator():\n",
    "    errors.append(compute_classification_accuracy(x_data, y_data))\n",
    "print(\"Train accuracy: %.3f\" % (np.mean(np.array(errors))))\n",
    "\n",
    "errors = []\n",
    "for x_data, y_data in from_cache_generator(False):\n",
    "    errors.append(compute_classification_accuracy(x_data, y_data))\n",
    "print(\"Test accuracy: %.3f\" % (np.mean(np.array(errors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
