{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from time import sleep, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER_PATH = '/Users/aref/dvs-dataset/DvsGesture'\n",
    "\n",
    "nb_image_height = 64\n",
    "nb_image_weight = 64\n",
    "nb_inputs  = nb_image_height*nb_image_weight\n",
    "nb_hidden  = 128\n",
    "nb_outputs = 12\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu...\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda...')\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    print('using cpu...')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file list:\n",
    "train_trail_file = 'trials_to_train.txt'\n",
    "test_trail_file = 'trials_to_test.txt'\n",
    "\n",
    "def load_trail_files(trail_file):\n",
    "    file_list = []\n",
    "    with open(os.path.join(DATASET_FOLDER_PATH, trail_file), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            aedat_file = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            csv_file = aedat_file.replace('.aedat', '_labels.csv')\n",
    "            file_list.append((\n",
    "                os.path.join(DATASET_FOLDER_PATH, aedat_file),\n",
    "                os.path.join(DATASET_FOLDER_PATH, csv_file)\n",
    "            ))\n",
    "    return file_list\n",
    "\n",
    "file_list_train = load_trail_files(train_trail_file)\n",
    "file_list_test = load_trail_files(test_trail_file)\n",
    "\n",
    "def get_label(timestamp):\n",
    "    for t in event_labels.keys():\n",
    "        if t > timestamp:\n",
    "            return event_labels[t]\n",
    "    return 0\n",
    "\n",
    "def get_label_text(timestamp):\n",
    "    return gesture_mapping[get_label(timestamp)]\n",
    "\n",
    "# mapping\n",
    "gesture_mapping = {\n",
    "    0: 'no_gesture',\n",
    "    1: 'hand_clapping',\n",
    "    2: 'right_hand_wave',\n",
    "    3: 'left_hand_wave',\n",
    "    4: 'right_arm_clockwise',\n",
    "    5: 'right_arm_counter_clockwise',\n",
    "    6: 'left_arm_clockwise',\n",
    "    7: 'left_arm_counter_clockwise',\n",
    "    8: 'arm_roll',\n",
    "    9: 'air_drums',\n",
    "    10: 'air_guitar',\n",
    "    11: 'other_gestures',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_cache_generator(train_set=True):\n",
    "    counter = 0\n",
    "    file_list = file_list_train if train_set else file_list_test\n",
    "    for file_name_set in file_list:\n",
    "        counter += 1\n",
    "        x_train = np.load(file=\"cache/x_train_cache_%d.npy\" % counter)\n",
    "        y_train = np.load(file=\"cache/y_train_cache_%d.npy\" % counter)\n",
    "        yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, x_local, y_local, optimizer, epoch, logging_interval=100):\n",
    "    # This method is derived from: \n",
    "    # https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "    # Was licensed BSD-3-clause\n",
    "    \n",
    "    print '>>>>>>>>>>>>>>', x_local.shape\n",
    "    print '>>>>>>>>>>>>>>', y_local.shape\n",
    "    model.train()\n",
    "    for d, t in zip(x_local, y_local):\n",
    "        d, t = d.to(device), t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(d)\n",
    "        target = torch.ones_like(output) * t\n",
    "        loss = F.nll_loss(output, target.type(torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(zip(x_local, y_local)):\n",
    "#         print '~~~~~~~~~~~~~~~~~~~~>', target\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         print output.shape, '~>', target.shape\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if batch_idx % logging_interval == 0:\n",
    "#             pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "#             correct = pred.eq(target.view_as(pred)).float().mean().item()\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} Accuracy: {:.2f}%'.format(\n",
    "#                 epoch, batch_idx * len(data), len([1]),\n",
    "#                 100. * batch_idx / x_local.size(0), loss.item(),\n",
    "#                 100. * correct))\n",
    "\n",
    "def test(model, device, x_local, y_local):\n",
    "    # This method is derived from: \n",
    "    # https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "    # Was licensed BSD-3-clause\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in zip(x_local, y_local):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # Note: with `reduce=True`, I'm not sure what would happen with a final batch size \n",
    "            # that would be smaller than regular previous batch sizes. For now it works.\n",
    "            test_loss += F.nll_loss(output, target, reduce=True).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_set_loader.dataset)\n",
    "    print(\"\")\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, \n",
    "        correct, len([1]),\n",
    "        100. * correct / len([1])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingNeuronLayerRNN(nn.Module):\n",
    "    def __init__(self, device, n_inputs, n_hidden, decay_multiplier=0.9, threshold=2.0, penalty_threshold=2.5):\n",
    "        super(SpikingNeuronLayerRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.decay_multiplier = decay_multiplier\n",
    "        self.threshold = threshold\n",
    "        self.penalty_threshold = penalty_threshold\n",
    "        \n",
    "        self.fc = nn.Linear(n_inputs, n_hidden)\n",
    "        \n",
    "        self.init_parameters()\n",
    "        self.reset_state()\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def init_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            if param.dim() >= 2:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.prev_inner = torch.zeros([self.n_hidden]).to(self.device)\n",
    "        self.prev_outer = torch.zeros([self.n_hidden]).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Call the neuron at every time step.\n",
    "        \n",
    "        x: activated_neurons_below\n",
    "        \n",
    "        return: a tuple of (state, output) for each time step. Each item in the tuple\n",
    "        are then themselves of shape (batch_size, n_hidden) and are PyTorch objects, such \n",
    "        that the whole returned would be of shape (2, batch_size, n_hidden) if casted.\n",
    "        \"\"\"\n",
    "        if self.prev_inner.dim() == 1:\n",
    "            # Adding batch_size dimension directly after doing a `self.reset_state()`:\n",
    "            batch_size = x.shape[0]\n",
    "            self.prev_inner = torch.stack(batch_size * [self.prev_inner])\n",
    "            self.prev_outer = torch.stack(batch_size * [self.prev_outer])\n",
    "        \n",
    "        # 1. Weight matrix multiplies the input x\n",
    "        input_excitation = self.fc(x)\n",
    "        \n",
    "        # 2. We add the result to a decayed version of the information we already had.\n",
    "        inner_excitation = input_excitation + self.prev_inner * self.decay_multiplier\n",
    "        \n",
    "        # 3. We compute the activation of the neuron to find its output value, \n",
    "        #    but before the activation, there is also a negative bias that refrain thing from firing too much.\n",
    "        outer_excitation = F.relu(inner_excitation - self.threshold)\n",
    "        \n",
    "        # 4. If the neuron fires, the activation of the neuron is subtracted to its inner state \n",
    "        #    (and with an extra penalty for increase refractory time), \n",
    "        #    because it discharges naturally so it shouldn't fire twice. \n",
    "        do_penalize_gate = (outer_excitation > 0).float()\n",
    "        # TODO: remove following /2?\n",
    "        inner_excitation = inner_excitation - (self.penalty_threshold/self.threshold * inner_excitation) * do_penalize_gate\n",
    "        \n",
    "        # 5. The outer excitation has a negative part after the positive part. \n",
    "        outer_excitation = outer_excitation #+ torch.abs(self.prev_outer) * self.decay_multiplier / 2.0\n",
    "        \n",
    "        # 6. Setting internal values before returning. \n",
    "        #    And the returning value is the one of the previous time step to delay \n",
    "        #    activation of 1 time step of \"processing\" time. For logits, we don't take activation.\n",
    "        delayed_return_state = self.prev_inner\n",
    "        delayed_return_output = self.prev_outer\n",
    "        self.prev_inner = inner_excitation\n",
    "        self.prev_outer = outer_excitation\n",
    "        return delayed_return_state, delayed_return_output\n",
    "\n",
    "\n",
    "class InputDataToSpikingPerceptronLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        super(InputDataToSpikingPerceptronLayer, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.reset_state()\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        #     self.prev_state = torch.zeros([self.n_hidden]).to(self.device)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, is_2D=True):\n",
    "        return x\n",
    "#         x = x.view(x.size(0), -1)  # Flatten 2D image to 1D for FC\n",
    "#         random_activation_perceptron = torch.rand(x.shape).to(self.device)\n",
    "#         return random_activation_perceptron * x\n",
    "\n",
    "\n",
    "class OutputDataToSpikingPerceptronLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, average_output=True):\n",
    "        \"\"\"\n",
    "        average_output: might be needed if this is used within a regular neural net as a layer.\n",
    "        Otherwise, sum may be numerically more stable for gradients with setting average_output=False.\n",
    "        \"\"\"\n",
    "        super(OutputDataToSpikingPerceptronLayer, self).__init__()\n",
    "        if average_output:\n",
    "            self.reducer = lambda x, dim: x.sum(dim=dim)\n",
    "        else:\n",
    "            self.reducer = lambda x, dim: x.mean(dim=dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if type(x) == list:\n",
    "            x = torch.stack(x)\n",
    "        return self.reducer(x, 0)\n",
    "\n",
    "\n",
    "class SpikingNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        super(SpikingNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.n_time_steps = nb_steps\n",
    "        \n",
    "        self.input_conversion = InputDataToSpikingPerceptronLayer(device)\n",
    "        \n",
    "        \n",
    "        self.layer1 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=nb_inputs, n_hidden=nb_hidden,\n",
    "            decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5\n",
    "        )\n",
    "        \n",
    "        self.layer2 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=nb_hidden, n_hidden=nb_outputs,\n",
    "            decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5\n",
    "        )\n",
    "        \n",
    "        self.output_conversion = OutputDataToSpikingPerceptronLayer(average_output=False)  # Sum on outputs.\n",
    "        \n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward_through_time(self, x):\n",
    "        \"\"\"\n",
    "        This acts as a layer. Its input is non-time-related, and its output too.\n",
    "        So the time iterations happens inside, and the returned layer is thus\n",
    "        passed through global average pooling on the time axis before the return \n",
    "        such as to be able to mix this pipeline with regular backprop layers such\n",
    "        as the input data and the output data.\n",
    "        \"\"\"\n",
    "        self.input_conversion.reset_state()\n",
    "        self.layer1.reset_state()\n",
    "        self.layer2.reset_state()\n",
    "\n",
    "        out = []\n",
    "        \n",
    "        all_layer1_states = []\n",
    "        all_layer1_outputs = []\n",
    "        all_layer2_states = []\n",
    "        all_layer2_outputs = []\n",
    "        for counter in range(self.n_time_steps):\n",
    "            xi = self.input_conversion(x[counter, :])\n",
    "            \n",
    "            # For layer 1, we take the regular output.\n",
    "            layer1_state, layer1_output = self.layer1(xi)\n",
    "            \n",
    "            # We take inner state of layer 2 because it's pre-activation and thus acts as out logits.\n",
    "            layer2_state, layer2_output = self.layer2(layer1_output)\n",
    "            \n",
    "            all_layer1_states.append(layer1_state)\n",
    "            all_layer1_outputs.append(layer1_output)\n",
    "            all_layer2_states.append(layer2_state)\n",
    "            all_layer2_outputs.append(layer2_output)\n",
    "            out.append(layer2_state)\n",
    "            \n",
    "        out = self.output_conversion(out)\n",
    "        return out, [[all_layer1_states, all_layer1_outputs], [all_layer2_states, all_layer2_outputs]]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.forward_through_time(x)\n",
    "        return F.log_softmax(out, dim=-1)\n",
    "\n",
    "    def visualize_all_neurons(self, x):\n",
    "        assert x.shape[0] == 1 and len(x.shape) == 4, (\n",
    "            \"Pass only 1 example to SpikingNet.visualize(x) with outer dimension shape of 1.\")\n",
    "        _, layers_state = self.forward_through_time(x)\n",
    "\n",
    "        for i, (all_layer_states, all_layer_outputs) in enumerate(layers_state):\n",
    "            layer_state  =  torch.stack(all_layer_states).data.cpu().numpy().squeeze().transpose()\n",
    "            layer_output = torch.stack(all_layer_outputs).data.cpu().numpy().squeeze().transpose()\n",
    "            \n",
    "            self.plot_layer(layer_state, title=\"Inner state values of neurons for layer {}\".format(i))\n",
    "            self.plot_layer(layer_output, title=\"Output spikes (activation) values of neurons for layer {}\".format(i))\n",
    "    \n",
    "    def visualize_neuron(self, x, layer_idx, neuron_idx):\n",
    "        assert x.shape[0] == 1 and len(x.shape) == 4, (\n",
    "            \"Pass only 1 example to SpikingNet.visualize(x) with outer dimension shape of 1.\")\n",
    "        _, layers_state = self.forward_through_time(x)\n",
    "\n",
    "        all_layer_states, all_layer_outputs = layers_state[layer_idx]\n",
    "        layer_state  =  torch.stack(all_layer_states).data.cpu().numpy().squeeze().transpose()\n",
    "        layer_output = torch.stack(all_layer_outputs).data.cpu().numpy().squeeze().transpose()\n",
    "\n",
    "        self.plot_neuron(layer_state[neuron_idx], title=\"Inner state values neuron {} of layer {}\".format(neuron_idx, layer_idx))\n",
    "        self.plot_neuron(layer_output[neuron_idx], title=\"Output spikes (activation) values of neuron {} of layer {}\".format(neuron_idx, layer_idx))\n",
    "\n",
    "    def plot_layer(self, layer_values, title):\n",
    "        \"\"\"\n",
    "        This function is derived from: \n",
    "            https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition \n",
    "        Which was released under the MIT License. \n",
    "        \"\"\"\n",
    "        width = max(16, layer_values.shape[0] / 8)\n",
    "        height = max(4, layer_values.shape[1] / 8)\n",
    "        plt.figure(figsize=(width, height))\n",
    "        plt.imshow(\n",
    "            layer_values,\n",
    "            interpolation=\"nearest\",\n",
    "            cmap=plt.cm.rainbow\n",
    "        )\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Neurons of layer\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_neuron(self, neuron_through_time, title):\n",
    "        width = max(16, len(neuron_through_time) / 8)\n",
    "        height = 4\n",
    "        plt.figure(figsize=(width, height))\n",
    "        plt.title(title)\n",
    "        plt.plot(neuron_through_time)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Neuron's activation\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_epochs(model): \n",
    "    def _train(epoch, lr):\n",
    "        optimizer = optim.SGD(model.parameters(), lr, momentum=0.5)\n",
    "        for x_data, y_data in from_cache_generator():\n",
    "#             if print_counter % 4 == 0:\n",
    "#                 print '.',\n",
    "#             print_counter += 1\n",
    "            \n",
    "            y_data = y_data.astype(np.long)\n",
    "            max_count = x_data.shape[0] / batch_size\n",
    "            for counter in range(max_count):\n",
    "                i = counter*batch_size\n",
    "                x_local = torch.from_numpy(x_data[i:i+batch_size, :, :]).type(dtype)\n",
    "                y_local = torch.from_numpy(y_data[i:i+batch_size])\n",
    "\n",
    "                if x_local.shape[0] != batch_size:\n",
    "                    continue\n",
    "            \n",
    "                train(model, device, x_local, y_local, optimizer, epoch, logging_interval=10)\n",
    "#         test(model, device, test_set_loader)\n",
    "\n",
    "\n",
    "    _train(1, 0.1)\n",
    "    _train(2, 0.05)\n",
    "    _train(3, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'cache/x_train_cache_1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b8c07d248e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mspiking_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpikingNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_many_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspiking_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-902fefb9ffc5>\u001b[0m in \u001b[0;36mtrain_many_epochs\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-902fefb9ffc5>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(epoch, lr)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrom_cache_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#             if print_counter % 4 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#                 print '.',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5c9a3e03f570>\u001b[0m in \u001b[0;36mfrom_cache_generator\u001b[0;34m(train_set)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_name_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cache/x_train_cache_%d.npy\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cache/y_train_cache_%d.npy\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'cache/x_train_cache_1.npy'"
     ]
    }
   ],
   "source": [
    "spiking_model = SpikingNet(device)\n",
    "train_many_epochs(spiking_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
