{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from time import sleep, time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER_PATH = '/Users/aref/dvs-dataset/DvsGesture'\n",
    "\n",
    "nb_image_height = 64\n",
    "nb_image_weight = 64\n",
    "nb_inputs  = nb_image_height*nb_image_weight\n",
    "nb_hidden  = 128 #256\n",
    "nb_outputs = 12\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu...\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda...')\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    print('using cpu...')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file list:\n",
    "train_trail_file = 'trials_to_train.txt'\n",
    "test_trail_file = 'trials_to_test.txt'\n",
    "\n",
    "def load_trail_files(trail_file):\n",
    "    file_list = []\n",
    "    with open(os.path.join(DATASET_FOLDER_PATH, trail_file), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            aedat_file = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            csv_file = aedat_file.replace('.aedat', '_labels.csv')\n",
    "            file_list.append((\n",
    "                os.path.join(DATASET_FOLDER_PATH, aedat_file),\n",
    "                os.path.join(DATASET_FOLDER_PATH, csv_file)\n",
    "            ))\n",
    "    return file_list\n",
    "\n",
    "file_list_train = load_trail_files(train_trail_file)\n",
    "file_list_test = load_trail_files(test_trail_file)\n",
    "\n",
    "def get_label(event_labels, timestamp):\n",
    "    for t in event_labels.keys():\n",
    "        if t > timestamp:\n",
    "            return event_labels[t]\n",
    "    return 0\n",
    "\n",
    "def get_label_text(event_labels, timestamp):\n",
    "    return gesture_mapping[get_label(event_labels, timestamp)]\n",
    "\n",
    "# mapping\n",
    "gesture_mapping = {\n",
    "    0: 'no_gesture',\n",
    "    1: 'hand_clapping',\n",
    "    2: 'right_hand_wave',\n",
    "    3: 'left_hand_wave',\n",
    "    4: 'right_arm_clockwise',\n",
    "    5: 'right_arm_counter_clockwise',\n",
    "    6: 'left_arm_clockwise',\n",
    "    7: 'left_arm_counter_clockwise',\n",
    "    8: 'arm_roll',\n",
    "    9: 'air_drums',\n",
    "    10: 'air_guitar',\n",
    "    11: 'other_gestures',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import read_file_all\n",
    "from collections import OrderedDict\n",
    "\n",
    "def read_event_labels(path):\n",
    "    label_began_time = None\n",
    "    event_labels = OrderedDict()\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            label, start, end = line.strip().split(',')\n",
    "#             print '%5s\\t%15s\\t%15s' % (label, start, end)\n",
    "            try:\n",
    "                label = int(label)\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if label_began_time is None:\n",
    "                label_began_time = start\n",
    "\n",
    "            event_labels[start] = 0\n",
    "            event_labels[end] = label\n",
    "    return event_labels, label_began_time\n",
    "\n",
    "\n",
    "def cache_trail_set_from_file_list(trail, file_list):\n",
    "    counter = 0\n",
    "    for file_name_set in file_list:\n",
    "        x_train = np.zeros([0, 100, nb_inputs])\n",
    "        y_train = []\n",
    "        counter += 1\n",
    "        print '%d out of %d ----------------------------------------------------------' % (counter, len(file_list))\n",
    "        print '    reading \"%s\"' % file_name_set[0]\n",
    "        event_labels, label_began_time = read_event_labels(file_name_set[1])\n",
    "        event_list = read_file_all(file_name_set[0])\n",
    "\n",
    "        print('    processing file')\n",
    "        img = np.zeros([nb_image_weight, nb_image_height])\n",
    "\n",
    "        max_time = None\n",
    "        min_time = None\n",
    "        begin_time = None\n",
    "        end_time = None\n",
    "\n",
    "        prev_label = None\n",
    "        frame_counter = 0\n",
    "        x_frame = np.zeros([1, 100, nb_inputs])\n",
    "        for e in event_list:\n",
    "            if e != 'clear':\n",
    "                img[int(e['y']/2), int(e['x']/2)] = 1 # if e['polarity'] == 1 else 0\n",
    "                if e['timestamp'] < min_time or min_time is None:\n",
    "                    min_time = e['timestamp']\n",
    "                if e['timestamp'] > max_time or max_time is None:\n",
    "                    max_time = e['timestamp']\n",
    "            else:\n",
    "                if begin_time is None:\n",
    "                    begin_time = min_time\n",
    "                end_time = max_time\n",
    "                mean_time = (max_time + min_time)/2\n",
    "                mean_time = mean_time - begin_time + label_began_time\n",
    "                label = get_label(event_labels, mean_time)\n",
    "                max_time = None\n",
    "                min_time = None\n",
    "                if prev_label is None:\n",
    "                    prev_label = label\n",
    "                elif prev_label != label:\n",
    "                    prev_label = None\n",
    "                    x_frame = np.zeros([1, 100, nb_inputs])\n",
    "                    img = np.zeros([nb_image_weight, nb_image_height])\n",
    "                    frame_counter = 0\n",
    "                    continue\n",
    "\n",
    "                if frame_counter == 100:\n",
    "                    y_train.append(label)\n",
    "                    x_train = np.append(x_train, x_frame, axis=0)\n",
    "                    x_frame = np.zeros([1, 100, nb_inputs])\n",
    "                    frame_counter = 0\n",
    "                else:\n",
    "                    x_frame[0, frame_counter, :] = img.flatten()\n",
    "                    frame_counter += 1\n",
    "                img = np.zeros([nb_image_weight, nb_image_height])\n",
    "\n",
    "        y_train = np.array(y_train)\n",
    "        print '    ', x_train.shape, ' ~> ', y_train.shape\n",
    "        np.save(file=\"x_%s_cache_%d\" % (trail, counter), arr=x_train)\n",
    "        np.save(file=\"y_%s_cache_%d\" % (trail, counter), arr=y_train)\n",
    "        print '    saved!'\n",
    "        \n",
    "# cache_trail_set_from_file_list('train', file_list_train)\n",
    "# cache_trail_set_from_file_list('test', file_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_cache_generator(train_set=True):\n",
    "    counter = 0\n",
    "    file_list = file_list_train if train_set else file_list_test\n",
    "    for file_name_set in file_list:\n",
    "        counter += 1\n",
    "        x_train = np.load(file=\"cache/x_train_cache_%d.npy\" % counter)\n",
    "        y_train = np.load(file=\"cache/y_train_cache_%d.npy\" % counter)\n",
    "        yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "w1 = torch.empty((nb_inputs+1, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden+1, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "loss_hist = []\n",
    "\n",
    "print('init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSpike(torch.autograd.Function):\n",
    "    scale = 50.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input/(SuperSpike.scale*torch.abs(input)+1.0)**2\n",
    "#         return grad_input\n",
    "    \n",
    "spike_fn  = SuperSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1[:-1, :]))\n",
    "    hr = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = [mem]\n",
    "    spk_rec = [mem]\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = torch.zeros_like(mem)\n",
    "        c   = (mthr > 0)\n",
    "        rst[c] = torch.ones_like(mem)[c]\n",
    "       \n",
    "        rs =  torch.ones_like(mem)\n",
    "        for i in range(batch_size):\n",
    "            rs[i,:] = w1[-1, :]\n",
    "        rs[mthr <= 0] = 0\n",
    "        \n",
    "        new_syn = alpha*syn +h1[:,t] +rs\n",
    "        new_mem = beta*mem +syn -rst\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2[:-1, :]))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        rs = torch.ones_like(out)\n",
    "        for i in range(batch_size):\n",
    "            rs[i,:] = w2[-1, :]\n",
    "        rs[out <= 0] = 0\n",
    "        \n",
    "        new_flt = alpha*flt +h2[:,t] +rs\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr=2e-3, nb_epochs=10, loss_hist=None):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    if loss_hist is None:\n",
    "        loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        print_counter = 0\n",
    "        local_loss = []\n",
    "        for x_data, y_data in from_cache_generator():\n",
    "            if print_counter % 4 == 0:\n",
    "                print '.',\n",
    "            print_counter += 1\n",
    "            \n",
    "            y_data = y_data.astype(np.long)\n",
    "            max_count = x_data.shape[0] / batch_size\n",
    "            for counter in range(max_count):\n",
    "                i = counter*batch_size\n",
    "                x_local = torch.from_numpy(x_data[i:i+batch_size, :, :]).type(dtype)\n",
    "                y_local = torch.from_numpy(y_data[i:i+batch_size])\n",
    "\n",
    "                if x_local.shape[0] != batch_size:\n",
    "                    continue\n",
    "                \n",
    "                output,_ = run_snn(x_local)\n",
    "                m,_=torch.max(output,1)\n",
    "                log_p_y = log_softmax_fn(m)\n",
    "                loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "                local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(x_data, y_data):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    max_count = len(x_data) / batch_size\n",
    "    for counter in range(max_count):\n",
    "        i = counter*batch_size\n",
    "        x_local = torch.from_numpy(x_data[i:i+batch_size, :, :]).type(dtype)\n",
    "        y_local = torch.from_numpy(y_data[i:i+batch_size])\n",
    "        output, _ = run_snn(x_local)\n",
    "        m, _ = torch.max(output,1) # max over time\n",
    "        _, am = torch.max(m,1)      # argmax over output units\n",
    "        tmp = np.mean((y_local.type(torch.long)==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_values():\n",
    "    errors = []\n",
    "    for x_data, y_data in from_cache_generator():\n",
    "        errors.append(compute_classification_accuracy(x_data, y_data))\n",
    "    print(\"Train accuracy: %.3f\" % (np.mean(np.array(errors))))\n",
    "\n",
    "    errors = []\n",
    "    for x_data, y_data in from_cache_generator(False):\n",
    "        errors.append(compute_classification_accuracy(x_data, y_data))\n",
    "    print(\"Test accuracy: %.3f\" % (np.mean(np.array(errors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "_last_time_length = None\n",
    "_iteration_left = None\n",
    "\n",
    "def expector_timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        global _last_time_length, _iteration_left\n",
    "        t_start = time()\n",
    "        \n",
    "        if _last_time_length is not None:\n",
    "            expectation = t_start\n",
    "            if _iteration_left is not None:\n",
    "                expectation +=  _last_time_length * _iteration_left\n",
    "            else:\n",
    "                expectation +=  _last_time_length\n",
    "            datestr = datetime.fromtimestamp(expectation).strftime(\"%H:%M:%S\")\n",
    "            print '[expecting to finish at %s]' % datestr\n",
    "        res = func(*args, **kwargs)\n",
    "        length = time() - t_start\n",
    "        print '[operation took %ds]' % length\n",
    "        print '[operation finished at %s]' % datetime.fromtimestamp(time()).strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        if _last_time_length is None:\n",
    "            _last_time_length = length\n",
    "        else:\n",
    "            _last_time_length = .9 * _last_time_length + .1 * length\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "@expector_timer\n",
    "def train_once():\n",
    "    global loss_hist\n",
    "    loss_hist = train(lr=2e-4, nb_epochs=5, loss_hist=loss_hist)\n",
    "\n",
    "    plt.figure(figsize=(3.3,2),dpi=150)\n",
    "    plt.plot(loss_hist)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    sns.despine()\n",
    "    print_accuracy_values()\n",
    "    \n",
    "#     np.save(file=\"_checkpoint_%d\" % time(), arr=[w1, w2])\n",
    "    print('[check point saved.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . Epoch 1: loss=2.59586\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . Epoch 2: loss=2.31572\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . Epoch 3: loss=2.07615\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . Epoch 4: loss=1.99626\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . Epoch 5: loss=1.93361\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 495x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.438\n",
      "Test accuracy: 0.457\n",
      "[check point saved.]\n",
      "[operation took 6262s]\n",
      "[operation finished at 16:07:56]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_epochs = 1#2*5\n",
    "for i in range(max_epochs):\n",
    "    _iteration_left = max_epochs - i \n",
    "    train_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . . . . . . . . . . . . . . . . . . . . . . . . . Epoch 1: loss=1.22454\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . Epoch 2: loss=1.17718\n",
      ". . . . . . . . . . . . . . . . . . . . . . . ."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5f84db80940a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_iteration_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-134a17b1807d>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'[expecting to finish at %s]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatestr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'[operation took %ds]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-f15858a7e4e6>\u001b[0m in \u001b[0;36mtrain_once\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ba842b2e7508>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr, nb_epochs, loss_hist)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlocal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrom_cache_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5c9a3e03f570>\u001b[0m in \u001b[0;36mfrom_cache_generator\u001b[0;34m(train_set)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_name_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cache/x_train_cache_%d.npy\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cache/y_train_cache_%d.npy\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 433\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1+1+5\n",
    "max_epochs = 5\n",
    "for i in range(max_epochs):\n",
    "    _iteration_left = max_epochs - i \n",
    "    train_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
