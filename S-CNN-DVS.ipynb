{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "from utils import plot_spk_rec, plot_mem_rec, generate_random_silence_files\n",
    "from scnn import SNN\n",
    "from scnn.optim import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools Import\n",
    "from data.data_augmentor import data_augment, batchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda...')\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    print('using cpu...')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME\n",
    "my_laptop = False\n",
    "if my_laptop:\n",
    "    CACHE_FOLDER_PATH = \"/Users/aref/dvs-dataset/Cached\"\n",
    "    DATASET_FOLDER_PATH = \"/Users/aref/dvs-dataset/DvsGesture\"\n",
    "else:\n",
    "    CACHE_FOLDER_PATH = \"/home/aref/dataset/dvs-dataset\"\n",
    "    DATASET_FOLDER_PATH = \"/home/aref/dataset/dvs-dataset\"\n",
    "\n",
    "    \n",
    "def load_data(trail):\n",
    "    print('remove this')\n",
    "    trail = 'acc_test' # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Remove this >>>>>>>>>>>>>>>>\n",
    "    \n",
    "    if trail.startswith('acc'):\n",
    "        max_augmentation = 1\n",
    "        augmentation = False\n",
    "    else:\n",
    "        max_augmentation = 3 if trail == 'train' else 1\n",
    "        augmentation = True\n",
    "    \n",
    "    trail = trail.replace('acc_', '')\n",
    "    return batchify(\n",
    "        trail,\n",
    "        DATASET_FOLDER_PATH,\n",
    "        CACHE_FOLDER_PATH,\n",
    "        condition_limit=['natural'],\n",
    "        batch_size=batch_size,\n",
    "        augmentation=augmentation,\n",
    "        max_augmentation=max_augmentation,\n",
    "        frame=20\n",
    "    )\n",
    "\n",
    "# calculate train dataset size\n",
    "dataset_size = 0.\n",
    "for x_batch, y_batch in load_data('train'):\n",
    "    dataset_size += 1.\n",
    "    if dataset_size % 64 == 1:\n",
    "        print('\\rpre-processing dataset: %d' % dataset_size, end='')\n",
    "print('\\rpre-processing dataset: %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def plot_spikes_in_time(layer, batch_id=0):\n",
    "    if layer.IS_CONV:\n",
    "        _plot_spikes_conv(layer, batch_id)\n",
    "    else:\n",
    "        _plot_spikes_dense(layer, batch_id)\n",
    "\n",
    "\n",
    "def _plot_spikes_dense(layer, batch_id=0):\n",
    "    spk_rec_hist = layer.spk_rec_hist[batch_id]\n",
    "    mem_rec_hist = layer.mem_rec_hist[batch_id]\n",
    "    \n",
    "    for i in range(mem_rec_hist.shape[1]):\n",
    "        plt.plot(mem_rec_hist[:, i], label='mem')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Membrace Potential')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.plot(spk_rec_hist,'b.')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Spikes')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.matshow(spk_rec_hist)\n",
    "    plt.xlabel('Neuron')\n",
    "    plt.ylabel('Spike Time')\n",
    "    plt.axis([-1, spk_rec_hist.shape[1], -1, spk_rec_hist.shape[0]])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def _plot_spikes_conv(layer, batch_id=0):\n",
    "    spk_rec_hist = layer.spk_rec_hist[batch_id]\n",
    "    mem_rec_hist = layer.mem_rec_hist[batch_id]\n",
    "    \n",
    "    time_step = mem_rec_hist.shape[1]\n",
    "    channels = mem_rec_hist.shape[0]\n",
    "    rest_shape = mem_rec_hist.shape[2:]\n",
    "    \n",
    "    tmp_spk = np.zeros((time_step, channels, *rest_shape))\n",
    "    tmp_mem = np.zeros((time_step, channels, *rest_shape))\n",
    "    for i in range(time_step):\n",
    "        tmp_spk[i, :, :, :] = spk_rec_hist[:, i, :, :]\n",
    "        tmp_mem[i, :, :, :] = mem_rec_hist[:, i, :, :]\n",
    "    spk_rec_hist = tmp_spk\n",
    "    mem_rec_hist = tmp_mem\n",
    "    \n",
    "    flat_spk = np.reshape(spk_rec_hist, (time_step, channels*np.prod(mem_rec_hist.shape[2:])))\n",
    "    flat_mem = np.reshape(mem_rec_hist, (time_step, channels*np.prod(mem_rec_hist.shape[2:])))\n",
    "    \n",
    "    # Plot Flats\n",
    "    max_flats = 25\n",
    "    if flat_mem.shape[1] > max_flats:\n",
    "        inx = np.random.randint(flat_mem.shape[1], size=max_flats)\n",
    "        flat_spk = flat_spk[:, inx]\n",
    "        flat_mem = flat_mem[:, inx]\n",
    "    \n",
    "    for i in range(flat_mem.shape[1]):\n",
    "        plt.plot(flat_mem[:, i], label='mem')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Membrace Potential')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(flat_spk,'.')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Spikes')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.matshow(flat_spk, cmap=plt.cm.gray_r, origin=\"lower\", aspect='auto')\n",
    "    plt.xlabel('Neuron')\n",
    "    plt.ylabel ('Spike Time')\n",
    "    plt.axis([-1, flat_spk.shape[1], -1, flat_spk.shape[0]])\n",
    "    plt.show()\n",
    "    \n",
    "    # Visual Plots\n",
    "    max_visual = 5\n",
    "    \n",
    "#     debug_print(spk_rec_hist, 'spk', pytorch=False)\n",
    "#     debug_print(mem_rec_hist, 'mem', pytorch=False)\n",
    "\n",
    "    time_idx = list(range(0, time_step, int(time_step/max_visual)))\n",
    "    neur_idx = np.random.randint(mem_rec_hist.shape[1], size=max_visual)\n",
    "\n",
    "    gs = GridSpec(max_visual, max_visual)\n",
    "    plt.figure(figsize=(30, 20))\n",
    "\n",
    "#     counter = 0\n",
    "#     for n in neur_idx:\n",
    "#         for t in time_idx:\n",
    "#             if counter == 0:\n",
    "#                 a0 = ax = plt.subplot(gs[counter])\n",
    "#             else:\n",
    "#                 ax = plt.subplot(gs[counter], sharey=a0)\n",
    "#             ax.imshow(spk_rec_hist[t, n, :, :], cmap=plt.cm.gray_r, origin=\"lower\", aspect='auto')\n",
    "#             plt.title('t(%d) - n(%d)' % (t, n))\n",
    "#             counter += 1\n",
    "#     plt.show()\n",
    "    \n",
    "    gs = GridSpec(max_visual, max_visual)\n",
    "    plt.figure(figsize=(30, 20))\n",
    "\n",
    "    counter = 0\n",
    "    for n in neur_idx:\n",
    "        for t in time_idx:\n",
    "            if counter == 0:\n",
    "                a0 = ax = plt.subplot(gs[counter])\n",
    "            else:\n",
    "                ax = plt.subplot(gs[counter], sharey=a0)\n",
    "            ax.imshow(mem_rec_hist[t, n, :, :], cmap=plt.cm.gray_r, origin=\"lower\", aspect='auto')\n",
    "            plt.title('t(%d) - n(%d)' % (t, n))\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = SNN(device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "beta = float(np.exp(-time_step / tau_mem))\n",
    "weight_scale = 7*(1.0 - beta)\n",
    "\n",
    "\n",
    "# network.add_layer(NewSpiker,\n",
    "#     input_shape=4096,\n",
    "#     output_shape=128,\n",
    "                  \n",
    "#     w_init_mean=0.0,\n",
    "#     w_init_std=weight_scale\n",
    "# )\n",
    "\n",
    "network.add_conv3d(input_shape=(64,64),\n",
    "                   output_shape=(64,64),\n",
    "                   input_channels=1,\n",
    "                   output_channels=128,\n",
    "                   kernel_size=(1,5,5),\n",
    "                   dilation=(1,1,1),\n",
    "                   lateral_connections=False,\n",
    ")\n",
    "\n",
    "# network.add_layer(SpikingPool2DLayer, kernel_size=(2,2), output_channels=32)\n",
    "network.add_pool2d(kernel_size=(4,4), output_channels=128)\n",
    "\n",
    "\n",
    "# network.add_dense(\n",
    "#     input_shape=4096,\n",
    "#     output_shape=256,\n",
    "#    w_init_mean=0.006,\n",
    "# #     w_init_std=.96,\n",
    "#     lateral_connections=True\n",
    "# )\n",
    "\n",
    "# network.add_layer(SpikingDenseLayer,\n",
    "#     output_shape=256\n",
    "# )\n",
    "\n",
    "# network.add_layer(SpikingDenseLayer,\n",
    "#     output_shape=128,\n",
    "#     w_init_mean=.19\n",
    "# )\n",
    "\n",
    "network.add_readout(output_shape=12,\n",
    "                    time_reduction=\"max\" # mean or max\n",
    ")\n",
    "\n",
    "network.compile()\n",
    "network = network.to(network.device, network.dtype) # FIXME: this is a bug, fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for X_batch, _ in load_data('train'):\n",
    "    break\n",
    "\n",
    "network.predict(X_batch)\n",
    "\n",
    "for i,l in enumerate(network.layers):\n",
    "    if 'spk_rec_hist' in l.__dict__:\n",
    "        print(\"Layer {}: average number of spikes={:.4f}\".format(i, l.spk_rec_hist.mean()))\n",
    "        if l.HAS_PARAM:\n",
    "            plot_spikes_in_time(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# opt = RAdam(network.get_trainable_parameters())\n",
    "opt = torch.optim.SGD(network.get_trainable_parameters(), lr=1e-3, momentum=0.9)\n",
    "network.fit(load_data, epochs=nb_epochs, optimizer=opt, dataset_size=dataset_size)\n",
    "\n",
    "print('\\n----------------------------------------')\n",
    "train_accuracy = network.compute_classification_accuracy(load_data('train'))\n",
    "print(\"Final Train Accuracy=%.2f%%\"%(train_accuracy * 100.))\n",
    "test_accuracy = network.compute_classification_accuracy(load_data('test'))\n",
    "print(\"Final Test Accuracy=%.2f%%\"%(test_accuracy * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for X_batch, _ in load_data('train'):\n",
    "    break\n",
    "\n",
    "network.predict(X_batch)\n",
    "for i,l in enumerate(network.layers):\n",
    "    if 'spk_rec_hist' in l.__dict__:\n",
    "        print(\"Layer {}: average number of spikes={:.4f}\".format(i, l.spk_rec_hist.mean()))\n",
    "        if l.HAS_PARAM:\n",
    "            plot_spikes_in_time(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network(X_batch)\n",
    "\n",
    "# Plotting spike trains or membrane potential\n",
    "for i,l in enumerate(network.layers):\n",
    "    if not l.HAS_PARAM:\n",
    "        continue\n",
    "        \n",
    "    if isinstance(l, SpikingDenseLayer):\n",
    "        print(\"Layer {}: average number of spikes={:.4f}\".format(i,l.spk_rec_hist.mean()))\n",
    "        spk_rec = l.spk_rec_hist\n",
    "        plot_spk_rec(spk_rec, idx=batch_idx)\n",
    "    elif isinstance(l, SpikingConv2DLayer):\n",
    "        print(\"Layer {}: average number of spikes={:.4f}\".format(i,l.spk_rec_hist.mean()))\n",
    "        spk_rec = l.spk_rec_hist\n",
    "        plot_spk_rec(spk_rec.sum(1), idx=batch_idx)\n",
    "    else:\n",
    "        mem_rec = l.mem_rec_hist\n",
    "        plot_mem_rec(mem_rec, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
