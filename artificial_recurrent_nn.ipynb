{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv2D, MaxPooling2D, Flatten, TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from time_expector import TimeExpector\n",
    "from notify import notify\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_augmentor import data_augment, batchify\n",
    "from time_expector import TimeExpector\n",
    "from cache_generator import GESTURE_MAPPING\n",
    "\n",
    "CACHE_FOLDER_PATH = \"/Users/aref/dvs-dataset/Cached/\"\n",
    "DATASET_FOLDER_PATH = \"/Users/aref/dvs-dataset/DvsGesture/\"\n",
    "    \n",
    "nb_image_height = 64\n",
    "nb_image_width  = 64\n",
    "nb_inputs  = nb_image_height*nb_image_width\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "batch_size = 128\n",
    "nb_epochs = 20\n",
    "nb_labels = len(GESTURE_MAPPING)\n",
    "\n",
    "tx = TimeExpector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(trail):\n",
    "    if trail.startswith('acc'):\n",
    "        max_augmentation = 1\n",
    "        augmentation = False\n",
    "    else:\n",
    "        max_augmentation = 3 if trail == 'train' else 1\n",
    "        augmentation = True\n",
    "    \n",
    "    trail = trail.replace('acc_', '')\n",
    "    return batchify(\n",
    "        trail,\n",
    "        DATASET_FOLDER_PATH,\n",
    "        CACHE_FOLDER_PATH,\n",
    "        condition_limit=['natural'],\n",
    "        batch_size=batch_size,\n",
    "        augmentation=augmentation,\n",
    "        max_augmentation=max_augmentation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prog_print(items, max_items):\n",
    "    percentage = 100*items/max_items\n",
    "    items = int(items)\n",
    "    max_items = int(max_items)\n",
    "    \n",
    "    stdout.write('\\r')\n",
    "    stdout.write('  %.2f%%' % percentage)\n",
    "    stdout.write('  [=')\n",
    "    if items < max_items:\n",
    "        stdout.write('=' * (items-1))\n",
    "        stdout.write('>')\n",
    "        stdout.write('.' * (max_items - items))\n",
    "    else:\n",
    "        stdout.write('=' * (items))\n",
    "    stdout.write(']  ')\n",
    "    stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keras_batch_size = 16\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'),\n",
    "                          input_shape=(None, 64, 64, 1),\n",
    "                          batch_size=keras_batch_size\n",
    "                         ))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(64,\n",
    "          batch_size=keras_batch_size,\n",
    "          stateful=True))\n",
    "\n",
    "model.add(Dense(nb_labels, activation='softmax'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model.add(TimeDistributedConvolution2D(32, 5, 5, border_mode='same', input_shape=(nb_steps, 64, 64)))\n",
    "# model.add(TimeDistributedMaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(TimeDistributedFlatten())\n",
    "# model.add(LSTM(256, return_sequences=True))\n",
    "\n",
    "# model.add(Dense(nb_labels))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ *A-RNN* has started\n",
      "Epoch 1/20\n",
      "  0.36%  [=>.......................................................]  \n",
      "\n",
      "-- canceled --\n"
     ]
    }
   ],
   "source": [
    "notify('*A-RNN* has started', mark='info')\n",
    "try:\n",
    "    for e in range(nb_epochs):\n",
    "        tx.tick(nb_epochs - e)\n",
    "        local_loss_train = []\n",
    "        local_loss_test = []\n",
    "        local_acc_train = []\n",
    "        local_acc_test = []\n",
    "\n",
    "        print 'Epoch %d/%d' % (e+1,nb_epochs)\n",
    "\n",
    "        pc = 0\n",
    "        for x_local, y_local in load_data('train'):\n",
    "            prog_print(pc, 55)\n",
    "            pc += .1\n",
    "\n",
    "            x_local = np.reshape(x_local, (batch_size, nb_steps, nb_image_width, nb_image_height, 1))\n",
    "            y_local = to_categorical(y_local)\n",
    "\n",
    "            history_train = model.fit(\n",
    "                x_local,\n",
    "                y_local,\n",
    "                batch_size=keras_batch_size,\n",
    "                epochs=1,\n",
    "                verbose=0\n",
    "            )\n",
    "            model.reset_states()\n",
    "            \n",
    "        for x_local, y_local in load_data('test'):\n",
    "            prog_print(pc, 55)\n",
    "            pc += .1\n",
    "            x_local = np.reshape(x_local, (batch_size, nb_steps, nb_image_width, nb_image_height, 1))\n",
    "            y_local = to_categorical(y_local)\n",
    "\n",
    "            history_test = model.evaluate(\n",
    "                x_local,\n",
    "                y_local,\n",
    "                batch_size=keras_batch_size,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "        mean_loss_train = np.mean(history_train.history['loss'])\n",
    "        mean_loss_test  = np.mean(history_test[0])\n",
    "        print('- loss (train=%.5f , test=%.5f)' % (mean_loss_train, mean_loss_test))\n",
    "        local_loss_train.append(mean_loss_train)\n",
    "        local_loss_test.append(mean_loss_test)\n",
    "\n",
    "        local_acc_train.append(np.mean(history_train.history['acc']))\n",
    "        local_acc_train.append(np.mean(history_test[1]))\n",
    "        tx.tock()\n",
    "    notify('*A-RNN* finished!', mark='ok')\n",
    "except KeyboardInterrupt:\n",
    "    print '\\n\\n-- canceled --'\n",
    "except:\n",
    "    notify('*A-RNN* failed...', mark='error')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
