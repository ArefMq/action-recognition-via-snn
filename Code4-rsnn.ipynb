{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7LS8QS1SwqG"
   },
   "source": [
    "# Spike - Recurrent Neural Netork\n",
    "\n",
    "-- more descriptions will be added --\n",
    "\n",
    "## Imports and CoLab checking\n",
    "In this section first we check if this code is running in the Google CoLab or in a Local Jupiter Notebook.\n",
    "Afterwad, the proper libraries will be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1569134854634,
     "user": {
      "displayName": "Aref Moqadam Mehr",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCxbdJgEIbVULHmf-R7ZArS6BsOAB7oEEfomXFbSg=s64",
      "userId": "11370787958799767643"
     },
     "user_tz": -210
    },
    "id": "sJf3bF_acmGS",
    "outputId": "0c8dd1cd-7005-4bbc-ff73-dd448b9389c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab: False\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print 'Colab:', IN_COLAB\n",
    "IN_NOTEBOOK = IN_COLAB or get_ipython().__class__.__name__ == 'ZMQInteractiveShell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45126,
     "status": "ok",
     "timestamp": 1569134902589,
     "user": {
      "displayName": "Aref Moqadam Mehr",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCxbdJgEIbVULHmf-R7ZArS6BsOAB7oEEfomXFbSg=s64",
      "userId": "11370787958799767643"
     },
     "user_tz": -210
    },
    "id": "Y4J5Med497zy",
    "outputId": "9063b652-ffa5-46fb-8184-c61e4cb29832"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !pip install -U -q PyDrive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    # Authenticate and create the PyDrive client.\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATASET_FOLDER_PATH = \"/content/drive/My Drive/ColabCodes/data/\"\n",
    "else:\n",
    "    DATASET_FOLDER_PATH = \"/Users/aref/dvs-dataset/\"\n",
    "    \n",
    "if not os.path.exists(DATASET_FOLDER_PATH):\n",
    "    raise Exception('can not access data folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqt3AxWf-xFH"
   },
   "outputs": [],
   "source": [
    "# numpy essentials imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# py-torch required imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# misc imports\n",
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJl-zBFYTjxH"
   },
   "source": [
    "## Reading Dataset\n",
    "This section is for reading the cached dataset from the defined path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygNkxZe8SmnP"
   },
   "outputs": [],
   "source": [
    "# mapping\n",
    "gesture_mapping = {\n",
    "    0: 'no_gesture',\n",
    "    1: 'hand_clapping',\n",
    "    2: 'right_hand_wave',\n",
    "    3: 'left_hand_wave',\n",
    "    4: 'right_arm_clockwise',\n",
    "    5: 'right_arm_counter_clockwise',\n",
    "    6: 'left_arm_clockwise',\n",
    "    7: 'left_arm_counter_clockwise',\n",
    "    8: 'arm_roll',\n",
    "    9: 'air_drums',\n",
    "    10: 'air_guitar',\n",
    "    11: 'other_gestures',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPZIedoVSmnM"
   },
   "outputs": [],
   "source": [
    "def data_loader(trail):\n",
    "    dataset_path = DATASET_FOLDER_PATH + 'cleaned_cache_' + trail\n",
    "    dataset_len = 98 if trail == 'train' else 24\n",
    "    \n",
    "    for counter in range(dataset_len):    \n",
    "        x_data = np.load(file='%s/x_%s_%d.npy' % (dataset_path, trail, counter+1))\n",
    "        y_data = np.load(file='%s/y_%s_%d.npy' % (dataset_path, trail, counter+1))\n",
    "        z_data = np.load(file='%s/z_%s_%d.npy' % (dataset_path, trail, counter+1))\n",
    "        \n",
    "        yield x_data, y_data, z_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBAAWB-XSmnR"
   },
   "outputs": [],
   "source": [
    "def serialize_events(x_data, y_data, z_data):    \n",
    "    scale_w = nb_image_weight / 128\n",
    "    scale_h = nb_image_height / 128\n",
    "    \n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    \n",
    "    x_series_instance = []\n",
    "    y_series_instance = []\n",
    "    \n",
    "    ev_times = z_data[:, 1]\n",
    "    frames = 0\n",
    "    max_time = np.max(ev_times)\n",
    "    current_time = np.min(ev_times)\n",
    "    while (current_time < max_time):\n",
    "        ev_lb = ev_times > current_time\n",
    "        ev_ub = ev_times < (current_time + retina_time_window_ms)\n",
    "\n",
    "        event_x = x_data[ev_lb & ev_ub, :]\n",
    "        event_y = y_data[ev_lb & ev_ub]\n",
    "\n",
    "        retina = np.zeros([nb_image_height, nb_image_weight])\n",
    "        retina[event_x[:,0] * scale_h, event_x[:,1] * scale_w] = 1\n",
    "\n",
    "        frame_y = np.round(np.median(event_y))\n",
    "\n",
    "        x_series_instance.append(retina.flatten())\n",
    "        y_series_instance.append(frame_y)\n",
    "        current_time += retina_time_window_ms\n",
    "        \n",
    "        frames += 1\n",
    "        if len(x_series_instance) == nb_steps:\n",
    "            batch_x.append(np.array(x_series_instance))\n",
    "            batch_y.append(np.round(np.median(np.array(y_series_instance))))\n",
    "            x_series_instance = []\n",
    "            y_series_instance = []\n",
    "            \n",
    "            if len(batch_x) == batch_size:\n",
    "                yield np.array(batch_x), np.array(batch_y)\n",
    "                batch_x = []\n",
    "                batch_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5N3Ed4pSmnO"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def visualize_dataset():\n",
    "    ev_times = z_data[:, 1]\n",
    "    frames = 0\n",
    "    max_time = np.max(ev_times)\n",
    "    current_time = np.min(ev_times)\n",
    "    while (current_time < max_time):\n",
    "        ev_lb = ev_times > current_time\n",
    "        ev_ub = ev_times < (current_time + retina_time_window_ms)\n",
    "\n",
    "        event_x = x_data[ev_lb & ev_ub, :]\n",
    "        event_y = y_data[ev_lb & ev_ub]\n",
    "\n",
    "        retina = np.zeros([128, 128])\n",
    "        retina[event_x[:,1], event_x[:,0]] = 1\n",
    "\n",
    "        frame_y = gesture_mapping[np.round(np.median(event_y))]\n",
    "\n",
    "        plt.imshow(retina)\n",
    "        plt.title(frame_y)\n",
    "        plt.show()\n",
    "        plt.pause(0.2)\n",
    "\n",
    "        frames += 1\n",
    "        if frames > 15:\n",
    "            break\n",
    "\n",
    "        current_time += retina_time_window_ms\n",
    "\n",
    "\n",
    "# visualize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iox9yWRiUFgE"
   },
   "source": [
    "## Network Architechture & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1569134929839,
     "user": {
      "displayName": "Aref Moqadam Mehr",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCxbdJgEIbVULHmf-R7ZArS6BsOAB7oEEfomXFbSg=s64",
      "userId": "11370787958799767643"
     },
     "user_tz": -210
    },
    "id": "a5ht6zsg1dUo",
    "outputId": "6b0e3f85-923c-4182-a7ab-c125c3af5dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu...\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda...')\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    print('using cpu...')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IBh_BH51EHN"
   },
   "outputs": [],
   "source": [
    "nb_image_height = 64\n",
    "nb_image_weight = 64\n",
    "nb_inputs  = nb_image_height*nb_image_weight\n",
    "nb_hidden  = 128\n",
    "nb_outputs = 12\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "retina_time_window_ms = 45 * 1000\n",
    "USE_RECURRENT_NEURONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98muZ6FH8_E1"
   },
   "outputs": [],
   "source": [
    "# tau_mem = 10e-3\n",
    "# tau_syn = 5e-3\n",
    "\n",
    "# alpha   = float(np.exp(-time_step/tau_syn))\n",
    "# beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJwU8meHcmGr"
   },
   "outputs": [],
   "source": [
    "class SpikingNeuronLayerRNN(nn.Module):\n",
    "    def __init__(self, device, n_inputs, n_hidden, decay_multiplier=0.9, threshold=2.0, penalty_threshold=2.5):\n",
    "        super(SpikingNeuronLayerRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.decay_multiplier = decay_multiplier\n",
    "        self.threshold = threshold\n",
    "        self.penalty_threshold = penalty_threshold\n",
    "        \n",
    "        self.fc = nn.Linear(n_inputs, n_hidden)\n",
    "        \n",
    "        self.init_parameters()\n",
    "        self.reset_state()\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def init_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            if param.dim() >= 2:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.prev_inner = torch.zeros([self.n_hidden]).to(self.device)\n",
    "        self.prev_outer = torch.zeros([self.n_hidden]).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Call the neuron at every time step.\n",
    "        \n",
    "        x: activated_neurons_below\n",
    "        \n",
    "        return: a tuple of (state, output) for each time step. Each item in the tuple\n",
    "        are then themselves of shape (batch_size, n_hidden) and are PyTorch objects, such \n",
    "        that the whole returned would be of shape (2, batch_size, n_hidden) if casted.\n",
    "        \"\"\"\n",
    "        if self.prev_inner.dim() == 1:\n",
    "            # Adding batch_size dimension directly after doing a `self.reset_state()`:\n",
    "            batch_size = x.shape[0]\n",
    "            self.prev_inner = torch.stack(batch_size * [self.prev_inner])\n",
    "            self.prev_outer = torch.stack(batch_size * [self.prev_outer])\n",
    "        \n",
    "        # 1. Weight matrix multiplies the input x\n",
    "        input_excitation = self.fc(x)\n",
    "        \n",
    "        # 2. We add the result to a decayed version of the information we already had.\n",
    "        inner_excitation = input_excitation + self.prev_inner * self.decay_multiplier\n",
    "        \n",
    "        # 3. We compute the activation of the neuron to find its output value, \n",
    "        #    but before the activation, there is also a negative bias that refrain thing from firing too much.\n",
    "        outer_excitation = F.relu(inner_excitation - self.threshold)\n",
    "        \n",
    "        # 4. If the neuron fires, the activation of the neuron is subtracted to its inner state \n",
    "        #    (and with an extra penalty for increase refractory time), \n",
    "        #    because it discharges naturally so it shouldn't fire twice. \n",
    "        do_penalize_gate = (outer_excitation > 0).float()\n",
    "        # TODO: remove following /2?\n",
    "        inner_excitation = inner_excitation - (self.penalty_threshold/self.threshold * inner_excitation) * do_penalize_gate\n",
    "        \n",
    "        # 5. The outer excitation has a negative part after the positive part. \n",
    "        outer_excitation = outer_excitation #+ torch.abs(self.prev_outer) * self.decay_multiplier / 2.0\n",
    "        \n",
    "        # 6. Setting internal values before returning. \n",
    "        #    And the returning value is the one of the previous time step to delay \n",
    "        #    activation of 1 time step of \"processing\" time. For logits, we don't take activation.\n",
    "        delayed_return_state = self.prev_inner\n",
    "        delayed_return_output = self.prev_outer\n",
    "        self.prev_inner = inner_excitation\n",
    "        self.prev_outer = outer_excitation\n",
    "        return delayed_return_state, delayed_return_output\n",
    "\n",
    "\n",
    "class InputDataToSpikingPerceptronLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        super(InputDataToSpikingPerceptronLayer, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.reset_state()\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        #     self.prev_state = torch.zeros([self.n_hidden]).to(self.device)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, is_2D=True):\n",
    "        return x\n",
    "#         x = x.view(x.size(0), -1)  # Flatten 2D image to 1D for FC\n",
    "#         random_activation_perceptron = torch.rand(x.shape).to(self.device)\n",
    "#         return random_activation_perceptron * x\n",
    "\n",
    "\n",
    "class OutputDataToSpikingPerceptronLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, average_output=True):\n",
    "        \"\"\"\n",
    "        average_output: might be needed if this is used within a regular neural net as a layer.\n",
    "        Otherwise, sum may be numerically more stable for gradients with setting average_output=False.\n",
    "        \"\"\"\n",
    "        super(OutputDataToSpikingPerceptronLayer, self).__init__()\n",
    "        if average_output:\n",
    "            self.reducer = lambda x, dim: x.sum(dim=dim)\n",
    "        else:\n",
    "            self.reducer = lambda x, dim: x.mean(dim=dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if type(x) == list:\n",
    "            x = torch.stack(x)\n",
    "        return self.reducer(x, 0)\n",
    "\n",
    "\n",
    "class SpikingNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        super(SpikingNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.n_time_steps = nb_steps\n",
    "        \n",
    "        self.input_conversion = InputDataToSpikingPerceptronLayer(device)\n",
    "        \n",
    "        \n",
    "        self.layer1 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=nb_inputs, n_hidden=nb_hidden,\n",
    "            decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5\n",
    "        )\n",
    "        \n",
    "        self.layer2 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=nb_hidden, n_hidden=nb_outputs,\n",
    "            decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5\n",
    "        )\n",
    "        \n",
    "        self.output_conversion = OutputDataToSpikingPerceptronLayer(average_output=False)  # Sum on outputs.\n",
    "        \n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward_through_time(self, x):\n",
    "        \"\"\"\n",
    "        This acts as a layer. Its input is non-time-related, and its output too.\n",
    "        So the time iterations happens inside, and the returned layer is thus\n",
    "        passed through global average pooling on the time axis before the return \n",
    "        such as to be able to mix this pipeline with regular backprop layers such\n",
    "        as the input data and the output data.\n",
    "        \"\"\"\n",
    "        self.input_conversion.reset_state()\n",
    "        self.layer1.reset_state()\n",
    "        self.layer2.reset_state()\n",
    "\n",
    "        out = []\n",
    "        \n",
    "        all_layer1_states = []\n",
    "        all_layer1_outputs = []\n",
    "        all_layer2_states = []\n",
    "        all_layer2_outputs = []\n",
    "        for counter in range(self.n_time_steps):\n",
    "            xi = self.input_conversion(x[counter, :])\n",
    "            \n",
    "            # For layer 1, we take the regular output.\n",
    "            layer1_state, layer1_output = self.layer1(xi)\n",
    "            \n",
    "            # We take inner state of layer 2 because it's pre-activation and thus acts as out logits.\n",
    "            layer2_state, layer2_output = self.layer2(layer1_output)\n",
    "            \n",
    "            all_layer1_states.append(layer1_state)\n",
    "            all_layer1_outputs.append(layer1_output)\n",
    "            all_layer2_states.append(layer2_state)\n",
    "            all_layer2_outputs.append(layer2_output)\n",
    "            out.append(layer2_state)\n",
    "            \n",
    "        out = self.output_conversion(out)\n",
    "        return out, [[all_layer1_states, all_layer1_outputs], [all_layer2_states, all_layer2_outputs]]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.forward_through_time(x)\n",
    "        return F.log_softmax(out, dim=-1)\n",
    "\n",
    "    def visualize_all_neurons(self, x):\n",
    "        assert x.shape[0] == 1 and len(x.shape) == 4, (\n",
    "            \"Pass only 1 example to SpikingNet.visualize(x) with outer dimension shape of 1.\")\n",
    "        _, layers_state = self.forward_through_time(x)\n",
    "\n",
    "        for i, (all_layer_states, all_layer_outputs) in enumerate(layers_state):\n",
    "            layer_state  =  torch.stack(all_layer_states).data.cpu().numpy().squeeze().transpose()\n",
    "            layer_output = torch.stack(all_layer_outputs).data.cpu().numpy().squeeze().transpose()\n",
    "            \n",
    "            self.plot_layer(layer_state, title=\"Inner state values of neurons for layer {}\".format(i))\n",
    "            self.plot_layer(layer_output, title=\"Output spikes (activation) values of neurons for layer {}\".format(i))\n",
    "    \n",
    "    def visualize_neuron(self, x, layer_idx, neuron_idx):\n",
    "        assert x.shape[0] == 1 and len(x.shape) == 4, (\n",
    "            \"Pass only 1 example to SpikingNet.visualize(x) with outer dimension shape of 1.\")\n",
    "        _, layers_state = self.forward_through_time(x)\n",
    "\n",
    "        all_layer_states, all_layer_outputs = layers_state[layer_idx]\n",
    "        layer_state  =  torch.stack(all_layer_states).data.cpu().numpy().squeeze().transpose()\n",
    "        layer_output = torch.stack(all_layer_outputs).data.cpu().numpy().squeeze().transpose()\n",
    "\n",
    "        self.plot_neuron(layer_state[neuron_idx], title=\"Inner state values neuron {} of layer {}\".format(neuron_idx, layer_idx))\n",
    "        self.plot_neuron(layer_output[neuron_idx], title=\"Output spikes (activation) values of neuron {} of layer {}\".format(neuron_idx, layer_idx))\n",
    "\n",
    "    def plot_layer(self, layer_values, title):\n",
    "        \"\"\"\n",
    "        This function is derived from: \n",
    "            https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition \n",
    "        Which was released under the MIT License. \n",
    "        \"\"\"\n",
    "        width = max(16, layer_values.shape[0] / 8)\n",
    "        height = max(4, layer_values.shape[1] / 8)\n",
    "        plt.figure(figsize=(width, height))\n",
    "        plt.imshow(\n",
    "            layer_values,\n",
    "            interpolation=\"nearest\",\n",
    "            cmap=plt.cm.rainbow\n",
    "        )\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Neurons of layer\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_neuron(self, neuron_through_time, title):\n",
    "        width = max(16, len(neuron_through_time) / 8)\n",
    "        height = 4\n",
    "        plt.figure(figsize=(width, height))\n",
    "        plt.title(title)\n",
    "        plt.plot(neuron_through_time)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Neuron's activation\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8loKExaocmGx"
   },
   "outputs": [],
   "source": [
    "# def compute_classification_accuracy(x_data, y_data):\n",
    "#     \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "#     accs = []\n",
    "#     max_count = len(x_data) / batch_size\n",
    "#     for counter in range(max_count):\n",
    "#         i = counter*batch_size\n",
    "#         x_local = torch.from_numpy(x_data[i:i+batch_size, :, :]).type(dtype)\n",
    "#         y_local = torch.from_numpy(y_data[i:i+batch_size])\n",
    "#         output, _ = run_snn(x_local)\n",
    "#         m, _ = torch.max(output,1) # max over time\n",
    "#         _, am = torch.max(m,1)      # argmax over output units\n",
    "#         tmp = np.mean((y_local.type(torch.long)==am).detach().cpu().numpy()) # compare to labels\n",
    "#         accs.append(tmp)\n",
    "#     return np.mean(accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9kOllEEcmG0"
   },
   "outputs": [],
   "source": [
    "# def print_accuracy_values():\n",
    "#     errors = []\n",
    "#     for x_data, y_data, z_data in data_loader('train'):\n",
    "#         errors.append(compute_classification_accuracy(x_data, y_data))\n",
    "#     print(\"Train accuracy: %.3f\" % (np.mean(np.array(errors))))\n",
    "\n",
    "#     errors = []\n",
    "#     for x_data, y_data, z_data in data_loader('test'):\n",
    "#         errors.append(compute_classification_accuracy(x_data, y_data))\n",
    "#     print(\"Test accuracy: %.3f\" % (np.mean(np.array(errors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqS3V9zvo_X-"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "_last_time_length = None\n",
    "_iteration_left = None\n",
    "\n",
    "def expector_timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        global _last_time_length\n",
    "        t_start = time()\n",
    "        \n",
    "        if _last_time_length is not None:\n",
    "            expectation = t_start\n",
    "            if _iteration_left is not None:\n",
    "                expectation +=  _last_time_length * _iteration_left\n",
    "            else:\n",
    "                expectation +=  _last_time_length\n",
    "            datestr = datetime.fromtimestamp(expectation).strftime(\"%H:%M:%S\")\n",
    "            print '[expecting to finish at %s]' % datestr\n",
    "        res = func(*args, **kwargs)\n",
    "        length = time() - t_start\n",
    "        print '[operation took %ds]' % length\n",
    "        print '[operation finished at %s]' % datetime.fromtimestamp(time()).strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        if _last_time_length is None:\n",
    "            _last_time_length = length\n",
    "        else:\n",
    "            _last_time_length = .9 * _last_time_length + .1 * length\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_r9ghplhcmG3"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# @expector_timer\n",
    "# def train_once():\n",
    "#     global loss_hist\n",
    "#     loss_hist = train(lr=2e-4, nb_epochs=5, loss_hist=loss_hist)\n",
    "\n",
    "#     plt.figure(figsize=(3.3,2),dpi=150)\n",
    "#     plt.plot(loss_hist)\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.show()\n",
    "#     sns.despine()\n",
    "#     print_accuracy_values()\n",
    "    \n",
    "#     np.save(file=\"_last_result\", arr=[w1, w2])\n",
    "#     print('[check point saved.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". >>>>>>>>>>>>>> torch.Size([2, 10, 4096])\n",
      ">>>>>>>>>>>>>> torch.Size([2])\n",
      "%%%%%%%%% torch.Size([4096, 12])\n",
      "torch.Size([4096, 12]) ~> torch.Size([4096, 12])\n",
      "**** "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() missing 1 required positional arguments: \"dim\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d58be9151f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mspiking_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpikingNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtrain_many_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspiking_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-55e175b1cb34>\u001b[0m in \u001b[0;36mtrain_many_epochs\u001b[0;34m(model, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0m_iteration_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0m_iteration_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-55e175b1cb34>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(epoch, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         test(model, device, test_set_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-eca32cb187f1>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'[expecting to finish at %s]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatestr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'[operation took %ds]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-d58be9151f74>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, x_local, y_local, optimizer, epoch, logging_interval)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'~>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'**** '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \"\"\"\n\u001b[1;32m   2333\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2334\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: max() missing 1 required positional arguments: \"dim\""
     ]
    }
   ],
   "source": [
    "@expector_timer\n",
    "def train(model, device, x_local, y_local, optimizer, epoch, logging_interval=100):\n",
    "    # This method is derived from: \n",
    "    # https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "    # Was licensed BSD-3-clause\n",
    "    \n",
    "    print '>>>>>>>>>>>>>>', x_local.shape\n",
    "    print '>>>>>>>>>>>>>>', y_local.shape\n",
    "    model.train()\n",
    "    for d, t in zip(x_local, y_local):\n",
    "        d, t = d.to(device), t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(d)\n",
    "        print '%%%%%%%%%', output.shape\n",
    "        target = torch.ones_like(output) * t\n",
    "        print output.shape, '~>', target.shape\n",
    "        loss = F.nll_loss(output, target.type(torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(zip(x_local, y_local)):\n",
    "#         print '~~~~~~~~~~~~~~~~~~~~>', target\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         print output.shape, '~>', target.shape\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if batch_idx % logging_interval == 0:\n",
    "#             pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "#             correct = pred.eq(target.view_as(pred)).float().mean().item()\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} Accuracy: {:.2f}%'.format(\n",
    "#                 epoch, batch_idx * len(data), len([1]),\n",
    "#                 100. * batch_idx / x_local.size(0), loss.item(),\n",
    "#                 100. * correct))\n",
    "\n",
    "def test(model, device, x_local, y_local):\n",
    "    # This method is derived from: \n",
    "    # https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "    # Was licensed BSD-3-clause\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in zip(x_local, y_local):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # Note: with `reduce=True`, I'm not sure what would happen with a final batch size \n",
    "            # that would be smaller than regular previous batch sizes. For now it works.\n",
    "            test_loss += F.nll_loss(output, target, reduce=True).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_set_loader.dataset)\n",
    "    print(\"\")\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, \n",
    "        correct, len([1]),\n",
    "        100. * correct / len([1])))\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "spiking_model = SpikingNet(device)\n",
    "train_many_epochs(spiking_model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4rO2nCQUwFw"
   },
   "source": [
    "## Spike Simulation\n",
    "Here is the code for simulating spikes as well as codes for training them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1569134932694,
     "user": {
      "displayName": "Aref Moqadam Mehr",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCxbdJgEIbVULHmf-R7ZArS6BsOAB7oEEfomXFbSg=s64",
      "userId": "11370787958799767643"
     },
     "user_tz": -210
    },
    "id": "Ttqb8uJicmGn",
    "outputId": "d7765234-9e33-4e7b-c481-ebe752087fde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "# if os.path.exists('_last_result') and ('w1' not in globals() or 'w2' not in globals()):\n",
    "#     w1, w2 = np.load(file=\"_last_result\")\n",
    "#     print 'continueing last progress'\n",
    "# else:\n",
    "#     weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "#     w1 = torch.empty(((nb_inputs+1) if USE_RECURRENT_NEURONS else nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "#     torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "#     w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "#     torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "#     loss_hist = []\n",
    "#     print('init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtUT7wkrcmGt"
   },
   "outputs": [],
   "source": [
    "# def run_snn(inputs):    \n",
    "#     if USE_RECURRENT_NEURONS:\n",
    "#         h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1[:-1]))\n",
    "#     else:\n",
    "#         h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "#     hr = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "#     syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "#     mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "#     mem_rec = [mem]\n",
    "#     spk_rec = [mem]\n",
    "\n",
    "#     # Compute hidden layer activity\n",
    "#     for t in range(nb_steps):\n",
    "#         mthr = mem-1.0\n",
    "#         out = spike_fn(mthr)\n",
    "#         rst = torch.zeros_like(mem)\n",
    "#         c   = (mthr > 0)\n",
    "#         rst[c] = torch.ones_like(mem)[c]\n",
    "       \n",
    "#         if USE_RECURRENT_NEURONS:\n",
    "#             rs =  torch.ones_like(mem)\n",
    "#             for i in range(batch_size):\n",
    "#                 rs[i,:] = w1[-1, :]\n",
    "#             rs[mthr <= 0] = 0.0\n",
    "#         else:\n",
    "#             rs = 0.0\n",
    "        \n",
    "#         new_syn = alpha*syn +h1[:,t] +rs\n",
    "#         new_mem = beta*mem +syn -rst\n",
    "\n",
    "#         mem = new_mem\n",
    "#         syn = new_syn\n",
    "\n",
    "#         mem_rec.append(mem)\n",
    "#         spk_rec.append(out)\n",
    "\n",
    "#     mem_rec = torch.stack(mem_rec,dim=1)\n",
    "#     spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "#     # Readout layer\n",
    "#     h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "#     flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "#     out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "#     out_rec = [out]\n",
    "#     for t in range(nb_steps):\n",
    "# #         rs = torch.ones_like(out)\n",
    "# #         for i in range(batch_size):\n",
    "# #             rs[i,:] = w2[-1, :]\n",
    "# #         rs[out <= 0] = 0\n",
    "        \n",
    "#         new_flt = alpha*flt +h2[:,t] #+rs\n",
    "#         new_out = beta*out +flt\n",
    "\n",
    "#         flt = new_flt\n",
    "#         out = new_out\n",
    "\n",
    "#         out_rec.append(out)\n",
    "\n",
    "#     out_rec = torch.stack(out_rec,dim=1)\n",
    "#     other_recs = [mem_rec, spk_rec]\n",
    "#     return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LT2dRIkcmGv"
   },
   "outputs": [],
   "source": [
    "# def train(lr=2e-3, nb_epochs=10, loss_hist=None):\n",
    "#     params = [w1,w2]\n",
    "#     optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "#     log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "#     loss_fn = nn.NLLLoss()\n",
    "    \n",
    "#     if loss_hist is None:\n",
    "#         loss_hist = []\n",
    "#     for e in range(nb_epochs):\n",
    "#         print_counter = 0\n",
    "#         local_loss = []\n",
    "#         for data_packet in data_loader('train'):\n",
    "#             if print_counter % 4 == 0:\n",
    "#                 print '.',\n",
    "#             print_counter += 1\n",
    "            \n",
    "#             for x_data, y_data in serialize_events(*data_packet):\n",
    "#                 x_local = torch.from_numpy(x_data).type(dtype)\n",
    "#                 y_local = torch.from_numpy(y_data.astype(np.long))\n",
    "                                \n",
    "#                 output,_ = run_snn(x_local)\n",
    "#                 m,_=torch.max(output,1)\n",
    "#                 log_p_y = log_softmax_fn(m)\n",
    "#                 loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss_val.backward()\n",
    "#                 optimizer.step()\n",
    "#                 local_loss.append(loss_val.item())\n",
    "#         mean_loss = np.mean(local_loss)\n",
    "#         print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "#         loss_hist.append(mean_loss)\n",
    "        \n",
    "#     return loss_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bmWRCWVhcmG6",
    "outputId": "22c2fa44-53af-4c50-c1e9-5178bba1ff31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . ."
     ]
    }
   ],
   "source": [
    "# max_epoch_counter = 1\n",
    "# for i in range(max_epoch_counter):\n",
    "#     _iteration_left = max_epoch_counter - i\n",
    "#     train_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_epochs(model, device): \n",
    "    def _train(epoch, lr):\n",
    "        optimizer = optim.SGD(model.parameters(), lr, momentum=0.5)\n",
    "        print_counter = 0\n",
    "        for data_packet in data_loader('train'):\n",
    "            if print_counter % 4 == 0:\n",
    "                print '.',\n",
    "            print_counter += 1\n",
    "            \n",
    "            for x_data, y_data in serialize_events(*data_packet):\n",
    "                x_local = torch.from_numpy(x_data).type(dtype).to(device)\n",
    "                y_local = torch.from_numpy(y_data.astype(np.long)).to(device)\n",
    "\n",
    "                if x_local.shape[0] != batch_size:\n",
    "                    continue\n",
    "            \n",
    "                train(model, device, x_local, y_local, optimizer, epoch, logging_interval=10)\n",
    "#         test(model, device, test_set_loader)\n",
    "\n",
    "    _iteration_left = 6\n",
    "    _train(1, 0.1)\n",
    "    _iteration_left = 5\n",
    "    _train(2, 0.05)\n",
    "    _iteration_left = 3\n",
    "    _train(3, 0.01)\n",
    "    _iteration_left = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". >>>>>>>>>>>>>> torch.Size([16, 100, 4096])\n",
      ">>>>>>>>>>>>>> torch.Size([16])\n",
      "%%%%%%%%% torch.Size([4096, 12])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "_thnn_nll_loss_forward not supported on CPUType for Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c7ec0db1bfef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspiking_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpikingNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_many_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspiking_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-55e175b1cb34>\u001b[0m in \u001b[0;36mtrain_many_epochs\u001b[0;34m(model, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0m_iteration_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0m_iteration_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-55e175b1cb34>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(epoch, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         test(model, device, test_set_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-eca32cb187f1>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'[expecting to finish at %s]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatestr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'[operation took %ds]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-bda46f6e2188>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, x_local, y_local, optimizer, epoch, logging_interval)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'%%%%%%%%%'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _thnn_nll_loss_forward not supported on CPUType for Long"
     ]
    }
   ],
   "source": [
    "# TODO check 'IN_NOTEBOOK' to either plot the output or not\n",
    "\n",
    "spiking_model = SpikingNet(device)\n",
    "train_many_epochs(spiking_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Code3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
